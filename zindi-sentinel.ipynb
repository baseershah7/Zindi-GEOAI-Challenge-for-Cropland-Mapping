{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec827f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:06.437232Z",
     "iopub.status.busy": "2025-08-19T16:46:06.436888Z",
     "iopub.status.idle": "2025-08-19T16:46:17.500732Z",
     "shell.execute_reply": "2025-08-19T16:46:17.499695Z"
    },
    "papermill": {
     "duration": 11.076198,
     "end_time": "2025-08-19T16:46:17.502479",
     "exception": false,
     "start_time": "2025-08-19T16:46:06.426281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rioxarray\r\n",
      "  Downloading rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Collecting rasterio\r\n",
      "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\r\n",
      "Collecting pystac_client\r\n",
      "  Downloading pystac_client-0.9.0-py3-none-any.whl.metadata (3.1 kB)\r\n",
      "Collecting planetary_computer\r\n",
      "  Downloading planetary_computer-1.0.0-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Collecting odc.stac\r\n",
      "  Downloading odc_stac-0.4.0-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting sentinelsat\r\n",
      "  Downloading sentinelsat-1.2.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting hvplot\r\n",
      "  Downloading hvplot-0.12.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting zarr\r\n",
      "  Downloading zarr-3.1.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from rioxarray) (25.0)\r\n",
      "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2025.3.1)\r\n",
      "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (1.26.4)\r\n",
      "Collecting affine (from rasterio)\r\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.6.15)\r\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1.2)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.0.9)\r\n",
      "Requirement already satisfied: requests>=2.28.2 in /usr/local/lib/python3.11/dist-packages (from pystac_client) (2.32.4)\r\n",
      "Collecting pystac>=1.10.0 (from pystac[validation]>=1.10.0->pystac_client)\r\n",
      "  Downloading pystac-1.13.0-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pystac_client) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pydantic>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from planetary_computer) (2.11.7)\r\n",
      "Requirement already satisfied: pytz>=2020.5 in /usr/local/lib/python3.11/dist-packages (from planetary_computer) (2025.2)\r\n",
      "Collecting python-dotenv (from planetary_computer)\r\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\r\n",
      "Collecting odc-geo>=0.4.7 (from odc.stac)\r\n",
      "  Downloading odc_geo-0.4.10-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Collecting odc-loader>=0.5.1 (from odc.stac)\r\n",
      "  Downloading odc_loader-0.5.1-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: dask[array] in /usr/local/lib/python3.11/dist-packages (from odc.stac) (2024.12.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from odc.stac) (2.2.3)\r\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from odc.stac) (1.0.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from odc.stac) (4.14.0)\r\n",
      "Collecting html2text (from sentinelsat)\r\n",
      "  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: geojson>=2 in /usr/local/lib/python3.11/dist-packages (from sentinelsat) (3.2.0)\r\n",
      "Requirement already satisfied: tqdm>=4.58 in /usr/local/lib/python3.11/dist-packages (from sentinelsat) (4.67.1)\r\n",
      "Collecting geomet (from sentinelsat)\r\n",
      "  Downloading geomet-1.1.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.11/dist-packages (from hvplot) (3.7.3)\r\n",
      "Requirement already satisfied: colorcet>=2 in /usr/local/lib/python3.11/dist-packages (from hvplot) (3.1.0)\r\n",
      "Requirement already satisfied: holoviews>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (1.20.2)\r\n",
      "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (1.7.1)\r\n",
      "Requirement already satisfied: param<3.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from hvplot) (2.2.1)\r\n",
      "Collecting donfig>=0.8 (from zarr)\r\n",
      "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr)\r\n",
      "  Downloading numcodecs-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (3.1.6)\r\n",
      "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (1.3.2)\r\n",
      "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (1.44.0)\r\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (11.2.1)\r\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (6.0.2)\r\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (6.5.1)\r\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->hvplot) (2025.4.0)\r\n",
      "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.19.0->hvplot) (3.0.6)\r\n",
      "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr)\r\n",
      "  Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->rioxarray) (2.4.1)\r\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from odc-geo>=0.4.7->odc.stac) (5.5.2)\r\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from odc-geo>=0.4.7->odc.stac) (2.1.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->odc.stac) (2025.2)\r\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (6.2.0)\r\n",
      "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (2.0.3)\r\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (3.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (3.0.0)\r\n",
      "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->hvplot) (0.4.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.7.3->planetary_computer) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.7.3->planetary_computer) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.7.3->planetary_computer) (0.4.1)\r\n",
      "Requirement already satisfied: jsonschema~=4.18 in /usr/local/lib/python3.11/dist-packages (from pystac[validation]>=1.10.0->pystac_client) (4.24.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pystac_client) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac_client) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac_client) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac_client) (2.5.0)\r\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[array]->odc.stac) (3.1.1)\r\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[array]->odc.stac) (2025.5.1)\r\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[array]->odc.stac) (1.4.2)\r\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[array]->odc.stac) (8.7.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask[array]->odc.stac) (3.23.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.1->hvplot) (3.0.2)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac_client) (2025.4.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac_client) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac_client) (0.25.1)\r\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[array]->odc.stac) (1.0.0)\r\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.0->hvplot) (0.5.1)\r\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.0->hvplot) (1.0.3)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.0->hvplot) (0.1.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23->rioxarray) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23->rioxarray) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23->rioxarray) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23->rioxarray) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23->rioxarray) (2024.2.0)\r\n",
      "Downloading rioxarray-0.19.0-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pystac_client-0.9.0-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading planetary_computer-1.0.0-py3-none-any.whl (14 kB)\r\n",
      "Downloading odc_stac-0.4.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentinelsat-1.2.1-py3-none-any.whl (48 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hvplot-0.12.0-py3-none-any.whl (175 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading zarr-3.1.1-py3-none-any.whl (255 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\r\n",
      "Downloading numcodecs-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading odc_geo-0.4.10-py3-none-any.whl (155 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading odc_loader-0.5.1-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pystac-1.13.0-py3-none-any.whl (206 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.8/206.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\r\n",
      "Downloading geomet-1.1.0-py3-none-any.whl (31 kB)\r\n",
      "Downloading html2text-2025.4.15-py3-none-any.whl (34 kB)\r\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\r\n",
      "Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-dotenv, html2text, geomet, donfig, crc32c, affine, sentinelsat, pystac, pystac_client, planetary_computer, rasterio, odc-geo, numcodecs, odc-loader, zarr, rioxarray, odc.stac, hvplot\r\n",
      "Successfully installed affine-2.4.0 crc32c-2.7.1 donfig-0.8.1.post1 geomet-1.1.0 html2text-2025.4.15 hvplot-0.12.0 numcodecs-0.16.2 odc-geo-0.4.10 odc-loader-0.5.1 odc.stac-0.4.0 planetary_computer-1.0.0 pystac-1.13.0 pystac_client-0.9.0 python-dotenv-1.1.1 rasterio-1.4.3 rioxarray-0.19.0 sentinelsat-1.2.1 zarr-3.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rioxarray rasterio pystac_client planetary_computer odc.stac sentinelsat hvplot zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6376db1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:17.526286Z",
     "iopub.status.busy": "2025-08-19T16:46:17.525938Z",
     "iopub.status.idle": "2025-08-19T16:46:25.071815Z",
     "shell.execute_reply": "2025-08-19T16:46:25.071039Z"
    },
    "papermill": {
     "duration": 7.559529,
     "end_time": "2025-08-19T16:46:25.073593",
     "exception": false,
     "start_time": "2025-08-19T16:46:17.514064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import pystac_client \n",
    "import planetary_computer\n",
    "from odc.stac import stac_load\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a454906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:25.099292Z",
     "iopub.status.busy": "2025-08-19T16:46:25.098634Z",
     "iopub.status.idle": "2025-08-19T16:46:25.104057Z",
     "shell.execute_reply": "2025-08-19T16:46:25.103133Z"
    },
    "papermill": {
     "duration": 0.019845,
     "end_time": "2025-08-19T16:46:25.105565",
     "exception": false,
     "start_time": "2025-08-19T16:46:25.085720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Orenburg (RU) – single Sentinel-2 tile footprint\n",
    "# lower_left  = (51.10, 55.00)   # (lat, lon)\n",
    "# upper_right = (51.50, 56.00)\n",
    "\n",
    "# # bounding box for fergana (uzbekistan)\n",
    "# lower_left  = (40.15, 70.75)        # (lat, lon)\n",
    "# upper_right = (40.55, 71.75)\n",
    "# 2000 m buffer: [70.98653092 39.99127677 73.00948379 42.01743359]\n",
    "# bounds = (lower_left[1], lower_left[0], upper_right[1], upper_right[0])\n",
    "# Fergana  chip: [70.93608325 39.97031454 73.09979272 42.02397519]\n",
    "# Orenburg chip: [53.86041435 50.94060491 56.04516069 53.02573486]\n",
    "\n",
    "bounds_fergana = (70.98653092, 39.99127677, 73.00948379, 42.01743359 )\n",
    "bounds_orenburg = (53.97714297, 50.9672661,  56.01383563, 53.0001858 )\n",
    "time_window = \"2021-07-01/2021-07-31\"\n",
    "time_window_fergana = \"2020-06-01/2020-08-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2531df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:25.129357Z",
     "iopub.status.busy": "2025-08-19T16:46:25.128459Z",
     "iopub.status.idle": "2025-08-19T16:46:25.907886Z",
     "shell.execute_reply": "2025-08-19T16:46:25.906994Z"
    },
    "papermill": {
     "duration": 0.792971,
     "end_time": "2025-08-19T16:46:25.909575",
     "exception": false,
     "start_time": "2025-08-19T16:46:25.116604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stac = pystac_client.Client.open('https://planetarycomputer.microsoft.com/api/stac/v1')\n",
    "search_fergana = stac.search(\n",
    "    bbox=bounds_fergana,\n",
    "    datetime=time_window_fergana,\n",
    "    collections=['sentinel-2-l2a'],\n",
    "    query={'eo:cloud_cover': {'lt': 5}},\n",
    ")\n",
    "search_orenburg = stac.search(\n",
    "    bbox=bounds_orenburg,\n",
    "    datetime=time_window,\n",
    "    collections=['sentinel-2-l2a'],\n",
    "    query={'eo:cloud_cover': {'lt': 5}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e51b9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:25.932349Z",
     "iopub.status.busy": "2025-08-19T16:46:25.932036Z",
     "iopub.status.idle": "2025-08-19T16:46:28.462086Z",
     "shell.execute_reply": "2025-08-19T16:46:28.461271Z"
    },
    "papermill": {
     "duration": 2.543133,
     "end_time": "2025-08-19T16:46:28.463673",
     "exception": false,
     "start_time": "2025-08-19T16:46:25.920540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentinel-2 scenes found :74\n",
      "==============\n",
      "Number of Sentinel-2 scenes found :65\n"
     ]
    }
   ],
   "source": [
    "items_fergana = list(search_fergana.get_items())\n",
    "print(f'Number of Sentinel-2 scenes found :{len(items_fergana)}')\n",
    "signed_items_fergana = [planetary_computer.sign(item) for item in items_fergana]\n",
    "\n",
    "print('==============')\n",
    "\n",
    "items_orenburg = list(search_orenburg.get_items())\n",
    "print(f'Number of Sentinel-2 scenes found :{len(items_orenburg)}')\n",
    "signed_items_orenburg = [planetary_computer.sign(item) for item in items_orenburg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb9c4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:28.486771Z",
     "iopub.status.busy": "2025-08-19T16:46:28.486492Z",
     "iopub.status.idle": "2025-08-19T16:46:28.491379Z",
     "shell.execute_reply": "2025-08-19T16:46:28.490294Z"
    },
    "papermill": {
     "duration": 0.018222,
     "end_time": "2025-08-19T16:46:28.492940",
     "exception": false,
     "start_time": "2025-08-19T16:46:28.474718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12', 'SCL', 'WVP', 'AOT']\n",
    "resolution = 30/111320.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad98840a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:28.516276Z",
     "iopub.status.busy": "2025-08-19T16:46:28.515493Z",
     "iopub.status.idle": "2025-08-19T16:46:31.273154Z",
     "shell.execute_reply": "2025-08-19T16:46:31.272299Z"
    },
    "papermill": {
     "duration": 2.771017,
     "end_time": "2025-08-19T16:46:31.274892",
     "exception": false,
     "start_time": "2025-08-19T16:46:28.503875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_fergana = stac_load(\n",
    "    signed_items_fergana,\n",
    "    bands=bands,\n",
    "    crs='EPSG:4326',\n",
    "    resolution=resolution,\n",
    "    chunks={'x':2048, 'y':2048},\n",
    "    dtype='uint16',\n",
    "    patch_url = planetary_computer.sign,\n",
    "    bbox=bounds_fergana,\n",
    ")\n",
    "# data_fergana = data_fergana.persist()\n",
    "# print('done')\n",
    "data_orenburg = stac_load(\n",
    "    signed_items_orenburg,\n",
    "    bands=bands,\n",
    "    crs='EPSG:4326',\n",
    "    resolution=resolution,\n",
    "    chunks={'x':2048, 'y':2048},\n",
    "    dtype='uint16',\n",
    "    patch_url = planetary_computer.sign,\n",
    "    bbox=bounds_orenburg,\n",
    ")\n",
    "# data_orenburg = data_orenburg.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268fac9",
   "metadata": {
    "papermill": {
     "duration": 0.010992,
     "end_time": "2025-08-19T16:46:31.297244",
     "exception": false,
     "start_time": "2025-08-19T16:46:31.286252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ede22b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:31.320789Z",
     "iopub.status.busy": "2025-08-19T16:46:31.320499Z",
     "iopub.status.idle": "2025-08-19T16:46:31.324486Z",
     "shell.execute_reply": "2025-08-19T16:46:31.323657Z"
    },
    "papermill": {
     "duration": 0.017373,
     "end_time": "2025-08-19T16:46:31.325840",
     "exception": false,
     "start_time": "2025-08-19T16:46:31.308467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unique_dates_fergana = data_fergana.time.dt.date.drop_duplicates(\"time\")\n",
    "# print(\"Unique dates:\", unique_dates_fergana.size)\n",
    "\n",
    "# first_per_day_fergana = data_fergana.groupby(\"time.date\").first()\n",
    "# data_fergana = first_per_day_fergana.rename(date=\"time\") \n",
    "\n",
    "# print('===========')\n",
    "\n",
    "# unique_dates_orenburg = data_orenburg.time.dt.date.drop_duplicates(\"time\")\n",
    "# print(\"Unique dates:\", unique_dates_orenburg.size)\n",
    "\n",
    "# first_per_day_orenburg = data_orenburg.groupby(\"time.date\").first()\n",
    "# data_orenburg = first_per_day_orenburg.rename(date=\"time\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d06fcf",
   "metadata": {
    "papermill": {
     "duration": 0.010391,
     "end_time": "2025-08-19T16:46:31.346988",
     "exception": false,
     "start_time": "2025-08-19T16:46:31.336597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d14cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:31.369732Z",
     "iopub.status.busy": "2025-08-19T16:46:31.369431Z",
     "iopub.status.idle": "2025-08-19T16:46:33.029776Z",
     "shell.execute_reply": "2025-08-19T16:46:33.029015Z"
    },
    "papermill": {
     "duration": 1.673596,
     "end_time": "2025-08-19T16:46:33.031357",
     "exception": false,
     "start_time": "2025-08-19T16:46:31.357761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates (Fergana): 18\n",
      "Unique dates (Orenburg): 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# -------------------------\n",
    "# Fergana\n",
    "# -------------------------\n",
    "unique_dates_fergana = data_fergana.time.dt.date.drop_duplicates(\"time\")\n",
    "print(\"Unique dates (Fergana):\", unique_dates_fergana.size)\n",
    "\n",
    "# group by date and mosaic tiles for each day\n",
    "mosaics_fergana = []\n",
    "for date, ds in data_fergana.groupby(\"time.date\"):\n",
    "    # take pixelwise max so valid pixels overwrite black nodata (0)\n",
    "    mosaic = ds.max(\"time\")\n",
    "    # assign correct date back\n",
    "    mosaic = mosaic.assign_coords(time=np.datetime64(date))\n",
    "    mosaics_fergana.append(mosaic)\n",
    "\n",
    "# combine into one dataset\n",
    "data_fergana = xr.concat(mosaics_fergana, dim=\"time\")\n",
    "\n",
    "# -------------------------\n",
    "# Orenburg\n",
    "# -------------------------\n",
    "unique_dates_orenburg = data_orenburg.time.dt.date.drop_duplicates(\"time\")\n",
    "print(\"Unique dates (Orenburg):\", unique_dates_orenburg.size)\n",
    "\n",
    "mosaics_orenburg = []\n",
    "for date, ds in data_orenburg.groupby(\"time.date\"):\n",
    "    mosaic = ds.max(\"time\")\n",
    "    mosaic = mosaic.assign_coords(time=np.datetime64(date))\n",
    "    mosaics_orenburg.append(mosaic)\n",
    "\n",
    "data_orenburg = xr.concat(mosaics_orenburg, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e910cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.055982Z",
     "iopub.status.busy": "2025-08-19T16:46:33.055357Z",
     "iopub.status.idle": "2025-08-19T16:46:33.059640Z",
     "shell.execute_reply": "2025-08-19T16:46:33.058973Z"
    },
    "papermill": {
     "duration": 0.017683,
     "end_time": "2025-08-19T16:46:33.060828",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.043145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import hvplot.xarray  # noqa\n",
    "# import panel as pn\n",
    "\n",
    "# # Downsample for speed\n",
    "# def downsample_for_view(da, factor=8):\n",
    "#     return da.coarsen(longitude=factor, latitude=factor, boundary=\"pad\").mean()\n",
    "\n",
    "# # Convert to RGB-friendly structure\n",
    "# def prep_rgb(ds):\n",
    "#     return downsample_for_view(ds[[\"B04\",\"B03\",\"B02\"]]).to_array(\"band\")\n",
    "\n",
    "# rgb_f = prep_rgb(data_fergana)\n",
    "# rgb_o = prep_rgb(data_orenburg)\n",
    "\n",
    "# # hvplot wants: r=, g=, b= mappings\n",
    "# def plot_rgb(da, title):\n",
    "#     return da.hvplot.rgb(\n",
    "#         x=\"longitude\", y=\"latitude\",\n",
    "#         r=\"B04\", g=\"B03\", b=\"B02\",\n",
    "#         clim=(0, 2500),  # scale like before\n",
    "#         frame_width=400, title=title,\n",
    "#         widget_type=\"scrubber\"  # makes it animatable\n",
    "#     )\n",
    "\n",
    "# plot_f = plot_rgb(data_fergana, \"Fergana\")\n",
    "# plot_o = plot_rgb(data_orenburg, \"Orenburg\")\n",
    "\n",
    "# pn.Row(plot_f, plot_o).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c90abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.083851Z",
     "iopub.status.busy": "2025-08-19T16:46:33.083534Z",
     "iopub.status.idle": "2025-08-19T16:46:33.088313Z",
     "shell.execute_reply": "2025-08-19T16:46:33.087549Z"
    },
    "papermill": {
     "duration": 0.017858,
     "end_time": "2025-08-19T16:46:33.089622",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.071764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# import numpy as np\n",
    "\n",
    "# # -----------------------------------------------------------\n",
    "# # 1.  One-time down-sample for speed\n",
    "# # -----------------------------------------------------------\n",
    "# def downsample_for_view(da, factor=8):\n",
    "#     return da.coarsen(longitude=factor, latitude=factor, boundary=\"pad\").mean()\n",
    "\n",
    "# rgb_f = downsample_for_view(\n",
    "#     data_fergana[[\"B04\",\"B03\",\"B02\"]].to_array(\"band\")\n",
    "# ).transpose(\"time\", \"latitude\", \"longitude\", \"band\")\n",
    "\n",
    "# rgb_o = downsample_for_view(\n",
    "#     data_orenburg[[\"B04\",\"B03\",\"B02\"]].to_array(\"band\")\n",
    "# ).transpose(\"time\", \"latitude\", \"longitude\", \"band\")\n",
    "\n",
    "# # -----------------------------------------------------------\n",
    "# # 2.  Helper to build an animation for one cube\n",
    "# # -----------------------------------------------------------\n",
    "# def quick_anim(rgb, title):\n",
    "#     n = rgb.sizes[\"time\"]\n",
    "#     fig, ax = plt.subplots(figsize=(5, 5))\n",
    "#     ax.set_title(f\"{title} — day 0\")\n",
    "#     im = ax.imshow(np.clip(rgb[0].values / 2500, 0, 1), origin=\"upper\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "#     def update(i):\n",
    "#         im.set_data(np.clip(rgb[i].values / 2500, 0, 1))\n",
    "#         ax.set_title(f\"{title} — {str(rgb.time[i].values)[:10]}\")\n",
    "#         return im,\n",
    "\n",
    "#     anim = FuncAnimation(fig, update, frames=n, interval=200, blit=True)\n",
    "#     plt.close(fig)          # keeps notebook clean\n",
    "#     return anim\n",
    "\n",
    "# # -----------------------------------------------------------\n",
    "# # 3.  Build two animations and show them inline\n",
    "# # -----------------------------------------------------------\n",
    "# anim_f = quick_anim(rgb_f, \"Fergana\")\n",
    "# # anim_o = quick_anim(rgb_o, \"Orenburg\")\n",
    "\n",
    "# # In a Jupyter cell:\n",
    "# from IPython.display import HTML\n",
    "# display(HTML(anim_f.to_jshtml()))\n",
    "# # display(HTML(anim_o.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee5e6cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.113272Z",
     "iopub.status.busy": "2025-08-19T16:46:33.112910Z",
     "iopub.status.idle": "2025-08-19T16:46:33.117499Z",
     "shell.execute_reply": "2025-08-19T16:46:33.116599Z"
    },
    "papermill": {
     "duration": 0.018304,
     "end_time": "2025-08-19T16:46:33.119028",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.100724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # valid_ratio = (data[[\"B04\",\"B03\",\"B02\"]] > 0).all(dim=\"time\").mean(dim=(\"longitude\",\"latitude\"))\n",
    "# # data = data.where(valid_ratio > 0.05, drop=True)\n",
    "\n",
    "# # valid_mask = (data[\"B04\"] > 0)  # True where valid, False where black/missing\n",
    "\n",
    "# # # Step 2: Compute % valid pixels per time slice\n",
    "# # valid_ratio = valid_mask.mean(dim=(\"longitude\", \"latitude\"))\n",
    "\n",
    "# # # Step 3: Keep only scenes with ≥95% valid pixels\n",
    "# # data = data.where(valid_ratio >= 0.95, drop=True)\n",
    "\n",
    "# # rgb_fergana = data_fergana[[\"B04\"]].to_array(dim=\"band\")\n",
    "# # scene_ok_fergana = (rgb_fergana > 0).all(\"band\").mean((\"longitude\", \"latitude\"))\n",
    "# # mask_fergana = scene_ok_fergana.compute() >= 0.8   \n",
    "# # rgb_orenburg = data_orenburg[[\"B04\"]].to_array(dim=\"band\")\n",
    "# # scene_ok_orenburg = (rgb_orenburg > 0).all(\"band\").mean((\"longitude\", \"latitude\"))\n",
    "# # mask_orenburg = scene_ok_orenburg.compute() >= 0.8   \n",
    "# # data_fergana = data_fergana.isel(time=mask_fergana)\n",
    "# # data_orenburg = data_orenburg.isel(time=mask_orenburg)\n",
    "# # print(f\"Remaining scenes: {data_fergana.time.size}\")\n",
    "# # print(f\"Remaining scenes: {data_orenburg.time.size}\")\n",
    "\n",
    "# # import xarray as xr  # Assuming already imported\n",
    "\n",
    "# # Define coarsen factor (e.g., 10 reduces spatial data by ~100x for mask calc)\n",
    "# coarsen_factor = 10\n",
    "\n",
    "# # For Fergana: Simplify and coarsen before mean\n",
    "# valid_frac_fergana = (data_fergana[\"B04\"].coarsen(longitude=coarsen_factor, latitude=coarsen_factor, boundary='pad').mean() > 0).mean((\"longitude\", \"latitude\"))\n",
    "# mask_fergana = valid_frac_fergana >= 0.8  # This is lazy\n",
    "# mask_fergana = mask_fergana.compute()  # Now compute (much smaller data)\n",
    "\n",
    "# # For Orenburg\n",
    "# valid_frac_orenburg = (data_orenburg[\"B04\"].coarsen(longitude=coarsen_factor, latitude=coarsen_factor, boundary='pad').mean() > 0).mean((\"longitude\", \"latitude\"))\n",
    "# mask_orenburg = valid_frac_orenburg >= 0.8\n",
    "# mask_orenburg = mask_orenburg.compute()\n",
    "\n",
    "# # Slice the data (original resolution preserved)\n",
    "# data_fergana = data_fergana.isel(time=mask_fergana)\n",
    "# data_orenburg = data_orenburg.isel(time=mask_orenburg)\n",
    "\n",
    "# print(f\"Remaining scenes Fergana: {data_fergana.time.size}\")\n",
    "# print(f\"Remaining scenes Orenburg: {data_orenburg.time.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c218ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.142371Z",
     "iopub.status.busy": "2025-08-19T16:46:33.141997Z",
     "iopub.status.idle": "2025-08-19T16:46:33.145634Z",
     "shell.execute_reply": "2025-08-19T16:46:33.144848Z"
    },
    "papermill": {
     "duration": 0.016601,
     "end_time": "2025-08-19T16:46:33.146940",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.130339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_scenes = len(data[\"time\"])\n",
    "# print(\"Scenes left after filter:\", n_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6120d0e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.236396Z",
     "iopub.status.busy": "2025-08-19T16:46:33.236030Z",
     "iopub.status.idle": "2025-08-19T16:46:33.239879Z",
     "shell.execute_reply": "2025-08-19T16:46:33.239048Z"
    },
    "papermill": {
     "duration": 0.017338,
     "end_time": "2025-08-19T16:46:33.241273",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.223935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = data.persist()\n",
    "# print(data)\n",
    "# display(data_orenburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4464b84f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.266353Z",
     "iopub.status.busy": "2025-08-19T16:46:33.265466Z",
     "iopub.status.idle": "2025-08-19T16:46:33.269695Z",
     "shell.execute_reply": "2025-08-19T16:46:33.268769Z"
    },
    "papermill": {
     "duration": 0.01767,
     "end_time": "2025-08-19T16:46:33.271139",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.253469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for band in bands:\n",
    "#     data.isel(time=0)[band].plot.imshow(cmap='viridis', robust=True)\n",
    "#     plt.title(f\"{band} Band\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d46d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.294888Z",
     "iopub.status.busy": "2025-08-19T16:46:33.294085Z",
     "iopub.status.idle": "2025-08-19T16:46:33.299461Z",
     "shell.execute_reply": "2025-08-19T16:46:33.298591Z"
    },
    "papermill": {
     "duration": 0.018554,
     "end_time": "2025-08-19T16:46:33.300841",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.282287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_data_fergana = data_fergana[[\"B04\",\"B03\",\"B02\"]].to_array()\n",
    "# plot_data_orenburg = data_orenburg[[\"B04\",\"B03\",\"B02\"]].to_array()\n",
    "\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# import xarray as xr  # Assuming this is already imported\n",
    "\n",
    "# # Define downsample factor (e.g., 4 reduces data by ~16x; increase for more speed)\n",
    "# downsample_factor = 4\n",
    "\n",
    "# # Function to downsample a single time step (fixed dims)\n",
    "# def downsample_frame(data, time_idx):\n",
    "#     return data.isel(time=time_idx).coarsen(\n",
    "#         longitude=downsample_factor, latitude=downsample_factor, boundary='pad'\n",
    "#     ).mean()\n",
    "\n",
    "# def precompute_frames(plot_data, downsample_factor):\n",
    "#     \"\"\"Return a list of coarse arrays already transposed to (lat, lon, band).\"\"\"\n",
    "#     frames = []\n",
    "#     for t in range(plot_data.sizes['time']):\n",
    "#         coarse = (plot_data.isel(time=t)\n",
    "#                   .coarsen(longitude=downsample_factor,\n",
    "#                            latitude=downsample_factor,\n",
    "#                            boundary='pad')\n",
    "#                   .mean()\n",
    "#                   .transpose('latitude', 'longitude', 'variable')\n",
    "#                   .values)\n",
    "#         frames.append(coarse)\n",
    "#     return frames\n",
    "\n",
    "# def create_animation_fast(frames, title_prefix):\n",
    "#     num_frames = len(frames)\n",
    "#     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "#     ax.axis('off')\n",
    "#     im = ax.imshow(frames[0], vmin=0, vmax=2500)\n",
    "#     title = ax.set_title(f\"{title_prefix} - Time 0\")\n",
    "\n",
    "#     def update(frame):\n",
    "#         im.set_data(frames[frame])\n",
    "#         title.set_text(f\"{title_prefix} - Time {frame}\")\n",
    "#         return im,\n",
    "\n",
    "#     anim = FuncAnimation(fig, update, frames=num_frames,\n",
    "#                          interval=500, blit=True)\n",
    "#     plt.close(fig)\n",
    "#     return anim\n",
    "\n",
    "# # ---- run once ----\n",
    "# frames_fergana = precompute_frames(plot_data_fergana, downsample_factor)\n",
    "# frames_orenburg = precompute_frames(plot_data_orenburg, downsample_factor)\n",
    "\n",
    "# # ---- build animations ----\n",
    "# anim_fergana  = create_animation_fast(frames_fergana,  \"Fergana\")\n",
    "# anim_orenburg = create_animation_fast(frames_orenburg, \"Orenburg\")\n",
    "\n",
    "# # In Jupyter, display with:\n",
    "# from IPython.display import HTML\n",
    "# HTML(anim_fergana.to_jshtml())\n",
    "# HTML(anim_orenburg.to_jshtml())\n",
    "\n",
    "# # Alternatively, save to file (e.g., for non-Jupyter use):\n",
    "# # anim_fergana.save('fergana_animation.gif', writer='pillow', fps=2)\n",
    "# # anim_orenburg.save('orenburg_animation.gif', writer='pillow', fps=2)\n",
    "# # plot_data_fergana.plot.imshow(col='time', col_wrap=4, robust=True, vmin=0, vmax=2500)\n",
    "# # plot_data_orenburg.plot.imshow(col='time', col_wrap=4, robust=True, vmin=0, vmax=2500)\n",
    "# # plt.show()\n",
    "# # rgb = data[[\"B04\",\"B03\",\"B02\"]].to_array(dim=\"band\")\n",
    "# # rgb = rgb.transpose(\"time\", \"latitude\", \"longitude\", \"band\")\n",
    "# # anim = rgb.plot.imshow(col=\"time\", robust=True, vmin=0, vmax=2500).animate()\n",
    "# # from matplotlib import rc\n",
    "# # rc('animation', html='jshtml')\n",
    "# # anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "488d7624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.324459Z",
     "iopub.status.busy": "2025-08-19T16:46:33.324118Z",
     "iopub.status.idle": "2025-08-19T16:46:33.328461Z",
     "shell.execute_reply": "2025-08-19T16:46:33.327427Z"
    },
    "papermill": {
     "duration": 0.017577,
     "end_time": "2025-08-19T16:46:33.329762",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.312185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# downsample_factor = 4\n",
    "\n",
    "# # For Fergana\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# downsampled_fergana = plot_data_fergana.isel(time=0).coarsen(\n",
    "#     x=downsample_factor, y=downsample_factor, boundary='pad' \n",
    "# ).mean() \n",
    "# downsampled_fergana.plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"demo date\")\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# # For Orenburg\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# downsampled_orenburg = plot_data_orenburg.isel(time=8).coarsen(\n",
    "#     x=downsample_factor, y=downsample_factor, boundary='pad'\n",
    "# ).mean()\n",
    "# downsampled_orenburg.plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"demo date\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9398b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.353786Z",
     "iopub.status.busy": "2025-08-19T16:46:33.353507Z",
     "iopub.status.idle": "2025-08-19T16:46:33.357666Z",
     "shell.execute_reply": "2025-08-19T16:46:33.356916Z"
    },
    "papermill": {
     "duration": 0.018181,
     "end_time": "2025-08-19T16:46:33.359022",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.340841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# median = data.median(dim='time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f41742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.382695Z",
     "iopub.status.busy": "2025-08-19T16:46:33.382413Z",
     "iopub.status.idle": "2025-08-19T16:46:33.386098Z",
     "shell.execute_reply": "2025-08-19T16:46:33.385400Z"
    },
    "papermill": {
     "duration": 0.017144,
     "end_time": "2025-08-19T16:46:33.387558",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.370414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# median[[\"B04\", \"B03\", \"B02\"]].to_array().plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"RGB Median Composite\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b5f530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.411509Z",
     "iopub.status.busy": "2025-08-19T16:46:33.410791Z",
     "iopub.status.idle": "2025-08-19T16:46:33.414724Z",
     "shell.execute_reply": "2025-08-19T16:46:33.413881Z"
    },
    "papermill": {
     "duration": 0.017551,
     "end_time": "2025-08-19T16:46:33.416318",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.398767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ndvi_median = (median.B08 - median.B04) / (median.B08 + median.B04)\n",
    "# # nvdi = nvdi.persist()\n",
    "# ndbi_median = (median.B11 - median.B08) / (median.B11 + median.B08)\n",
    "# ndwi_median = (median.B03 - median.B08) / (median.B03 + median.B08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253cda7",
   "metadata": {
    "papermill": {
     "duration": 0.010773,
     "end_time": "2025-08-19T16:46:33.438377",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.427604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Enhanced Vegetation Index(EVI)**\n",
    "\n",
    "**Soil-Adjusted Vegetation Index(SAVI)**\n",
    "\n",
    "**Modified Soil_Adjusted Vegetation Inde(MSAVI)**\n",
    "\n",
    "**Green Normalized Difference Vegetation Index (GNDVI)**\n",
    "\n",
    "**Index-Based Built-Up Index(IBI)**\n",
    "\n",
    "**Urban Index(UI)**\n",
    "\n",
    "**Normalized Difference Bare Soil Index(NDSI)**\n",
    "\n",
    "**Normalized Difference Moisture \n",
    "Index(NDMI)**\n",
    "\n",
    "**Normalized Difference Snow Index(NDSI)**\n",
    "\n",
    "**Brightness Index(BI)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737137d7",
   "metadata": {
    "papermill": {
     "duration": 0.0108,
     "end_time": "2025-08-19T16:46:33.460541",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.449741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weighted Mosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4418833e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T16:46:33.484320Z",
     "iopub.status.busy": "2025-08-19T16:46:33.483804Z",
     "iopub.status.idle": "2025-08-19T17:21:47.592289Z",
     "shell.execute_reply": "2025-08-19T17:21:47.591370Z"
    },
    "papermill": {
     "duration": 2114.12259,
     "end_time": "2025-08-19T17:21:47.594131",
     "exception": false,
     "start_time": "2025-08-19T16:46:33.471541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ULTRA-SAFE PROCESSING FOR KAGGLE\n",
      "============================================================\n",
      "Processing Fergana...\n",
      "============================================================\n",
      "[fergana] START   0.4 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  11%|█         | 2/18 [02:35<20:40, 77.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-06-15T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  17%|█▋        | 3/18 [04:20<22:35, 90.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-06-20T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  22%|██▏       | 4/18 [06:19<23:42, 101.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-06-25T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  28%|██▊       | 5/18 [07:43<20:35, 95.02s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-05T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  33%|███▎      | 6/18 [12:46<33:10, 165.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-07T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  39%|███▉      | 7/18 [14:47<27:43, 151.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-12T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  44%|████▍     | 8/18 [16:11<21:38, 129.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-15T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  50%|█████     | 9/18 [18:11<18:59, 126.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-22T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  56%|█████▌    | 10/18 [20:42<17:54, 134.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-07-30T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  61%|██████    | 11/18 [21:39<12:54, 110.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-01T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  67%|██████▋   | 12/18 [25:00<13:47, 137.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-06T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  72%|███████▏  | 13/18 [26:13<09:51, 118.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-14T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  78%|███████▊  | 14/18 [27:09<06:38, 99.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-16T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  83%|████████▎ | 15/18 [28:26<04:37, 92.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-19T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  89%|████████▉ | 16/18 [30:24<03:20, 100.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-21T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates:  94%|█████████▍| 17/18 [31:04<01:22, 82.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-24T00:00:00: 'Float64' object has no attribute 'value'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Processing dates: 100%|██████████| 18/18 [35:07<00:00, 117.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad date 2020-08-29T00:00:00: 'Float64' object has no attribute 'value'\n",
      "[fergana] Valid dates processed: 18 / 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[fergana] Computing mean: 100%|██████████| 13/13 [00:06<00:00,  2.11it/s]\n",
      "[fergana] Computing median:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITICAL ERROR: 'Float64' object has no attribute 'value'\n",
      "Try reducing chunk sizes further or processing fewer dates at a time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import gc\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import zarr  # Ensure zarr is imported\n",
    "\n",
    "def mem():\n",
    "    \"\"\"Current RAM in GB\"\"\"\n",
    "    return psutil.Process().memory_info().rss / 1024**3\n",
    "\n",
    "def _valid_mask(da, scl=None):\n",
    "    \"\"\"\n",
    "    True = usable pixel (not NaN, not black, not cloud).\n",
    "    da: DataArray for one band\n",
    "    scl: DataArray cloud mask (optional)\n",
    "    \"\"\"\n",
    "    not_nan   = ~xr.ufuncs.isnan(da)\n",
    "    not_black = (da != 0)          # adjust if your black value differs\n",
    "    mask      = not_nan & not_black\n",
    "    if scl is not None:\n",
    "        cloud = (scl == 8) | (scl == 9) | (scl == 10) | (scl == 11)\n",
    "        mask &= ~cloud\n",
    "    return mask.astype(\"float32\")   # 1=valid, 0=invalid\n",
    "\n",
    "def build_weighted_mosaic_ultra(data: xr.Dataset, prefix: str):\n",
    "    \"\"\"\n",
    "    data: xarray Dataset with dims (time, y, x) and bands + optional 'SCL'\n",
    "    prefix: 'fergana' or 'orenburg'\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"[{prefix}] START   {mem():.1f} GB\")\n",
    "    bands = [b for b in data.data_vars if b != \"SCL\"]\n",
    "    if not bands:\n",
    "        raise ValueError(\"No bands\")\n",
    "\n",
    "    # Initialize for weighted mean\n",
    "    running_sum = {}\n",
    "    weight_sum = None  # Will initialize with first valid\n",
    "\n",
    "    # For median, prepare temp zarr\n",
    "    temp_dir = f\"{prefix}_temp_zarr\"\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    first_append = {b: True for b in bands}\n",
    "\n",
    "    # Process each date incrementally\n",
    "    num_valid_dates = 0\n",
    "    for t in tqdm(data.time.values, desc=f\"[{prefix}] Processing dates\"):\n",
    "        try:\n",
    "            # Load this time slice\n",
    "            da_t = data.sel(time=t).load()\n",
    "            scl_t = da_t.get(\"SCL\")\n",
    "            valid_t = _valid_mask(da_t[bands[0]], scl_t)\n",
    "\n",
    "            # Skip if all invalid\n",
    "            if valid_t.sum() == 0:\n",
    "                print(f\"Skipping fully invalid date {t}\")\n",
    "                continue\n",
    "\n",
    "            num_valid_dates += 1\n",
    "\n",
    "            # Accumulate for mean\n",
    "            if weight_sum is None:\n",
    "                weight_sum = xr.zeros_like(valid_t)\n",
    "            weight_sum += valid_t\n",
    "\n",
    "            for b in bands:\n",
    "                band_t = da_t[b]\n",
    "                weighted = band_t * valid_t\n",
    "                if b not in running_sum:\n",
    "                    running_sum[b] = xr.zeros_like(weighted)\n",
    "                running_sum[b] += weighted\n",
    "\n",
    "            # Append to zarr for median\n",
    "            for b in bands:\n",
    "                valid_band = da_t[b].where(valid_t == 1, np.nan)\n",
    "                if first_append[b]:\n",
    "                    valid_band.expand_dims(time=[t]).to_zarr(temp_dir, mode='w', group=b, consolidated=True)\n",
    "                    first_append[b] = False\n",
    "                else:\n",
    "                    valid_band.expand_dims(time=[t]).to_zarr(temp_dir, append_dim='time', group=b, consolidated=True)\n",
    "\n",
    "            # Cleanup\n",
    "            del da_t, valid_t, scl_t\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping bad date {t}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if num_valid_dates == 0:\n",
    "        raise ValueError(\"No valid dates\")\n",
    "\n",
    "    print(f\"[{prefix}] Valid dates processed: {num_valid_dates} / {len(data.time)}\")\n",
    "\n",
    "    # Compute weighted mean\n",
    "    w_mean = {}\n",
    "    for b in tqdm(bands, desc=f\"[{prefix}] Computing mean\"):\n",
    "        w_mean[b] = xr.where(weight_sum > 0, running_sum[b] / weight_sum, np.nan)\n",
    "        del running_sum[b]  # Free mem\n",
    "        gc.collect()\n",
    "\n",
    "    mean_ds = xr.Dataset(w_mean)\n",
    "\n",
    "    # Compute weighted median from zarr\n",
    "    w_median = {}\n",
    "    for b in tqdm(bands, desc=f\"[{prefix}] Computing median\"):\n",
    "        z_da = xr.open_zarr(temp_dir, group=b, chunks='auto')[b]\n",
    "        w_median[b] = z_da.median(dim=\"time\", skipna=True).compute()\n",
    "        del z_da\n",
    "        gc.collect()\n",
    "\n",
    "    median_ds = xr.Dataset(w_median)\n",
    "\n",
    "    # Cleanup temp zarr\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "    # Save\n",
    "    mean_file   = f\"{prefix}_weighted_mean.tif\"\n",
    "    median_file = f\"{prefix}_weighted_median.tif\"\n",
    "    compress = dict(compress=\"lzw\", tiled=True)\n",
    "\n",
    "    mean_ds.rio.to_raster(mean_file, **compress)\n",
    "    median_ds.rio.to_raster(median_file, **compress)\n",
    "\n",
    "    print(f\"[{prefix}] SAVED   {mean_file}\")\n",
    "    print(f\"[{prefix}] SAVED   {median_file}\")\n",
    "    print(f\"[{prefix}] END     {mem():.1f} GB\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return mean_ds, median_ds\n",
    "\n",
    "# Ultra-safe usage - process one location at a time with maximum caution\n",
    "print(\"=\" * 60)\n",
    "print(\"ULTRA-SAFE PROCESSING FOR KAGGLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"Processing Fergana...\")\n",
    "    fergana_mean, fergana_median = build_weighted_mosaic_ultra(data_fergana, \"fergana\")\n",
    "    \n",
    "    # Aggressive cleanup before next location\n",
    "    del data_fergana, fergana_mean, fergana_median\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Processing Orenburg...\")\n",
    "    orenburg_mean, orenburg_median = build_weighted_mosaic_ultra(data_orenburg, \"orenburg\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ALL PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: {e}\")\n",
    "    print(\"Try reducing chunk sizes further or processing fewer dates at a time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3cae8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.625233Z",
     "iopub.status.busy": "2025-08-19T17:21:47.624430Z",
     "iopub.status.idle": "2025-08-19T17:21:47.629613Z",
     "shell.execute_reply": "2025-08-19T17:21:47.628592Z"
    },
    "papermill": {
     "duration": 0.022161,
     "end_time": "2025-08-19T17:21:47.630983",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.608822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Weighted Temporal Mosaicking\n",
    "# # # Assign weights based on cloud-free pixels (cloud mask using SCL band)\n",
    "# weights = ~((data_fergana[\"SCL\"] == 8) | \n",
    "#             (data_fergana[\"SCL\"] == 9) | \n",
    "#             (data_fergana[\"SCL\"] == 10) | \n",
    "#             (data_fergana[\"SCL\"] == 11))\n",
    "# weights = weights.astype(\"float32\")  # Convert to numeric mask\n",
    "# print('weights done')\n",
    "# # Build weighted mosaic\n",
    "# weighted_mosaic = {}\n",
    "# for band in data_fergana.data_vars.keys():\n",
    "#     if band == \"SCL\":  # skip classification band\n",
    "#         continue\n",
    "#     num = (data_fergana[band] * weights).sum(dim=\"time\")\n",
    "#     denom = weights.sum(dim=\"time\")\n",
    "#     weighted_mosaic[band] = xr.where(denom > 0, num / denom, float(\"nan\"))  # avoid div by zero\n",
    "\n",
    "# # Convert to dataset\n",
    "# weighted_mosaic_data = xr.Dataset(weighted_mosaic)\n",
    "# print('weighted mosaic done')\n",
    "# median_mosaic = {}\n",
    "# for band in data_fergana.data_vars.keys():\n",
    "#     if band == \"SCL\":\n",
    "#         continue\n",
    "#     valid = data_fergana[band].where(weights == 1)\n",
    "#     median_mosaic[band] = valid.median(dim=\"time\", skipna=True)\n",
    "\n",
    "# median_mosaic_data = xr.Dataset(median_mosaic)\n",
    "# print('median mosaic done')\n",
    "\n",
    "\n",
    "# weighted_mosaic_tiff_path = \"Sentinel2_WeightedMosaic_mean.tiff\"\n",
    "# weighted_mosaic_median_tiff_path = \"Sentinel2_WeightedMosaic_median.tiff\"\n",
    "# # weighted_mosaic_data = weighted_mosaic_data.persist()\n",
    "# # median_mosaic_data = median_mosaic_data.persist()\n",
    "# weighted_mosaic_data.rio.to_raster(\n",
    "#     \"weighted_mean_mosaic_fergana.tif\",\n",
    "#     tiled=True,\n",
    "#     windowed=True,\n",
    "#     compress=\"lzw\"\n",
    "# )\n",
    "# print('weighed mean mosaic saved')\n",
    "# median_mosaic_data.rio.to_raster(\n",
    "#     \"weighted_median_mosaic_fergana.tif\",\n",
    "#     tiled=True,\n",
    "#     windowed=True,\n",
    "#     compress=\"lzw\"\n",
    "# )\n",
    "# print('weighted median mosaic saved')\n",
    "# print(f\"Weighted mosaic GeoTIFF with all features saved at {weighted_mosaic_tiff_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6abf7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.660773Z",
     "iopub.status.busy": "2025-08-19T17:21:47.659856Z",
     "iopub.status.idle": "2025-08-19T17:21:47.664404Z",
     "shell.execute_reply": "2025-08-19T17:21:47.663383Z"
    },
    "papermill": {
     "duration": 0.020432,
     "end_time": "2025-08-19T17:21:47.665803",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.645371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted_mosaic_data = weighted_mosaic_data.compute()\n",
    "# rgb = weighted_mosaic_data[[\"B04\",\"B03\",\"B02\"]].to_array(\"band\") / 3000\n",
    "# rgb = rgb.clip(0, 1)   # use xarray's clip, not numpy’s\n",
    "\n",
    "# rgb.plot.imshow(\n",
    "#     col=\"band\", col_wrap=3, robust=True, cmap=\"viridis\"\n",
    "# )\n",
    "\n",
    "# # plt.imshow(np.transpose(rgb.values, (1,2,0)))\n",
    "# plt.title(\"Mosaic (Median Composite)\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c4b5729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.695676Z",
     "iopub.status.busy": "2025-08-19T17:21:47.694819Z",
     "iopub.status.idle": "2025-08-19T17:21:47.699149Z",
     "shell.execute_reply": "2025-08-19T17:21:47.698256Z"
    },
    "papermill": {
     "duration": 0.020818,
     "end_time": "2025-08-19T17:21:47.700625",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.679807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # after the cell above runs\n",
    "# var_names = list(weighted_mosaic_data.data_vars)\n",
    "# print(\"Variables in the single-scene dataset:\")\n",
    "# for v in var_names:\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bd2e9ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.730141Z",
     "iopub.status.busy": "2025-08-19T17:21:47.729469Z",
     "iopub.status.idle": "2025-08-19T17:21:47.733405Z",
     "shell.execute_reply": "2025-08-19T17:21:47.732632Z"
    },
    "papermill": {
     "duration": 0.019795,
     "end_time": "2025-08-19T17:21:47.734690",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.714895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 1. materialise the data\n",
    "# rgb = weighted_mosaic_data[[\"B04\",\"B03\",\"B02\"]].to_array(dim=\"band\") * 0.0001\n",
    "# rgb = rgb.transpose(\"latitude\",\"longitude\",\"band\").compute()\n",
    "\n",
    "# # 2. inspect actual value range\n",
    "# print(\"min:\", rgb.min().values, \"max:\", rgb.max().values)\n",
    "\n",
    "# # 3. plot\n",
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# rgb.plot.imshow(robust=True, ax=ax, vmin=0, vmax=0.35)\n",
    "# ax.set_title(\"RGB Composite (25 Jul)\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2de26bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.764283Z",
     "iopub.status.busy": "2025-08-19T17:21:47.763813Z",
     "iopub.status.idle": "2025-08-19T17:21:47.769971Z",
     "shell.execute_reply": "2025-08-19T17:21:47.769258Z"
    },
    "papermill": {
     "duration": 0.022576,
     "end_time": "2025-08-19T17:21:47.771287",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.748711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import rioxarray\n",
    "# from rasterio.enums import Resampling\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import xarray as xr\n",
    "\n",
    "# # def save_resampled_weighted_mosaics(\n",
    "# #     ds,\n",
    "# #     target_resolution=30,\n",
    "# #     methods=['bilinear', 'cubic'],\n",
    "# #     output_prefix='WeightedMosaic_30m'\n",
    "# # ):\n",
    "# #     \"\"\"\n",
    "# #     Resamples the weighted mosaic dataset to a specified resolution using multiple interpolation methods\n",
    "# #     and saves each resampled dataset as a separate GeoTIFF file.\n",
    "# #     Also prints per-band NaN statistics for diagnostic purposes.\n",
    "    \n",
    "# #     Parameters\n",
    "# #     ----------\n",
    "# #     ds : xarray.Dataset\n",
    "# #         The weighted mosaic dataset.\n",
    "# #     target_resolution : float, optional\n",
    "# #         Desired output resolution in meters (default=30).\n",
    "# #     methods : list of str, optional\n",
    "# #         Interpolation methods to apply (default=['bilinear', 'cubic']).\n",
    "# #     output_prefix : str, optional\n",
    "# #         Prefix for output filenames (default='WeightedMosaic_30m').\n",
    "# #     \"\"\"\n",
    "    \n",
    "# #     resampling_methods = {\n",
    "# #         'bilinear': Resampling.bilinear,\n",
    "# #         'cubic': Resampling.cubic\n",
    "# #     }\n",
    "# #     target_crs = \"EPSG:4326\"  # UTM Zone 18N for NYC\n",
    "    \n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     # 1) Set CRS correctly\n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     if not ds.rio.crs:\n",
    "# #         ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "# #         print(\"CRS set to EPSG:4326.\")\n",
    "# #     else:\n",
    "# #         print(f\"Existing CRS: {ds.rio.crs}\")\n",
    "    \n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     # 2) Rename dimensions if necessary\n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     if 'latitude' in ds.dims and 'longitude' in ds.dims:\n",
    "# #         ds = ds.rename({'latitude': 'y', 'longitude': 'x'})\n",
    "# #         print(\"Renamed (latitude->y, longitude->x) for spatial dims.\")\n",
    "    \n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     # 3) Resample each method\n",
    "# #     # ----------------------------------------------------------------\n",
    "# #     for method in methods:\n",
    "# #         if method not in resampling_methods:\n",
    "# #             print(f\"Skipping invalid method: {method}\")\n",
    "# #             continue\n",
    "\n",
    "# #         print(f\"\\n--- Processing {method.upper()} resampling ---\")\n",
    "        \n",
    "# #         try:\n",
    "# #             # Identify 2D spatial variables\n",
    "# #             spatial_vars = [var for var in ds.data_vars if ds[var].ndim == 2]\n",
    "# #             ds_filtered = ds[spatial_vars]\n",
    "            \n",
    "# #             processed_vars = {}\n",
    "# #             for var_name in spatial_vars:\n",
    "# #                 da = ds_filtered[var_name].astype(np.float32)\n",
    "                \n",
    "# #                 # Reproject to target CRS without setting nodata\n",
    "# #                 da_reproj = da.rio.reproject(\n",
    "# #                     dst_crs=target_crs,              # Correct keyword argument\n",
    "# #                     resolution=target_resolution,\n",
    "# #                     resampling=resampling_methods[method],\n",
    "# #                     nodata=None                       # Do not set nodata\n",
    "# #                 )\n",
    "# #                 processed_vars[var_name] = da_reproj\n",
    "            \n",
    "# #             # Rebuild dataset\n",
    "# #             ds_reproj = xr.Dataset(processed_vars)\n",
    "            \n",
    "# #             # Print NaN statistics\n",
    "# #             print(\"NaN Stats (after resampling) for each variable:\")\n",
    "# #             for var_name in spatial_vars:\n",
    "# #                 da_ = ds_reproj[var_name]\n",
    "# #                 nan_count = da_.isnull().sum().compute().item()\n",
    "# #                 total_count = da_.size\n",
    "# #                 min_val = da_.min().compute().item()\n",
    "# #                 max_val = da_.max().compute().item()\n",
    "# #                 nan_percentage = (nan_count / total_count) * 100\n",
    "# #                 print(f\"  {var_name}: NaNs={nan_count}/{total_count} ({nan_percentage:.2f}%), Min={min_val:.4f}, Max={max_val:.4f}\")\n",
    "            \n",
    "# #             # Define output path\n",
    "# #             output_path = f\"{output_prefix}_{method}.tiff\"\n",
    "# #             os.makedirs(os.path.dirname(output_prefix), exist_ok=True)\n",
    "            \n",
    "# #             # Save to GeoTIFF without nodata\n",
    "# #             ds_reproj[spatial_vars].rio.to_raster(\n",
    "# #                 output_path,\n",
    "# #                 dtype=\"float32\",\n",
    "# #                 compress=\"LZW\",\n",
    "# #                 tiled=True,\n",
    "# #                 nodata=None\n",
    "# #             )\n",
    "            \n",
    "# #             print(f\"✅ Saved resampled mosaic: {output_path}\")\n",
    "# #             print(f\"Output dimensions: {ds_reproj.dims}\")\n",
    "        \n",
    "# #         except Exception as e:\n",
    "# #             print(f\"❌ Error in {method} processing: {str(e)}\")\n",
    "# #             continue\n",
    "\n",
    "\n",
    "# # # Usage with your dataset:\n",
    "# # save_resampled_weighted_mosaics(weighted_mosaic_data, output_prefix='/kaggle/working/Sentinel2_Mosaic_bands_sampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17d0cf3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.801112Z",
     "iopub.status.busy": "2025-08-19T17:21:47.800790Z",
     "iopub.status.idle": "2025-08-19T17:21:47.807530Z",
     "shell.execute_reply": "2025-08-19T17:21:47.806748Z"
    },
    "papermill": {
     "duration": 0.023107,
     "end_time": "2025-08-19T17:21:47.808747",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.785640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from rasterio.transform import from_bounds\n",
    "# def resample_to_30m(ds, method=\"bilinear\"):\n",
    "#     \"\"\"\n",
    "#     Resamples Sentinel data from ~10m to ~30m (1/3 the resolution),\n",
    "#     using bilinear or cubic interpolation, \n",
    "#     while preserving the 'latitude' and 'longitude' dimension names in the output.\n",
    "\n",
    "#     Parameters:\n",
    "#     - ds : xarray.Dataset\n",
    "#         Sentinel dataset to resample (dims: 'time', 'latitude', 'longitude').\n",
    "#     - method : str\n",
    "#         Interpolation method ('bilinear' or 'cubic').\n",
    "\n",
    "#     Returns:\n",
    "#     - xarray.Dataset\n",
    "#         Resampled dataset with lat/lon dimension names restored.\n",
    "#     \"\"\"\n",
    "#     print(f\"Resampling data to ~30m using {method} interpolation...\")\n",
    "\n",
    "#     # Define resampling methods\n",
    "#     resampling_methods = {\n",
    "#         \"bilinear\": Resampling.bilinear,\n",
    "#         \"cubic\": Resampling.cubic\n",
    "#     }\n",
    "#     if method not in resampling_methods:\n",
    "#         raise ValueError(\"Invalid method. Choose 'bilinear' or 'cubic'.\")\n",
    "\n",
    "#     # Store original lat/lon range\n",
    "#     min_lat = float(ds.latitude.min().values)\n",
    "#     max_lat = float(ds.latitude.max().values)\n",
    "#     min_lon = float(ds.longitude.min().values)\n",
    "#     max_lon = float(ds.longitude.max().values)\n",
    "\n",
    "#     # Temporarily rename dims from (latitude, longitude) -> (y, x)\n",
    "#     ds_renamed = ds.rename_dims({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "#     ds_renamed = ds_renamed.rename_vars({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "\n",
    "#     # Let rioxarray know these are spatial dims in EPSG:4326\n",
    "#     ds_renamed = ds_renamed.rio.write_crs(\"EPSG:4326\", inplace=False)\n",
    "#     ds_renamed = ds_renamed.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=False)\n",
    "\n",
    "#     # Determine new shape (1/3 factor → integer downsampling)\n",
    "#     # e.g., if original ~10m, new ~30m => shape is 1/3 the original size\n",
    "#     new_height = ds.sizes[\"latitude\"] // 3\n",
    "#     new_width  = ds.sizes[\"longitude\"] // 3\n",
    "\n",
    "#     # Reproject/resample with the new shape\n",
    "#     resampled_ds = ds_renamed.rio.reproject(\n",
    "#         ds_renamed.rio.crs,\n",
    "#         resampling=resampling_methods[method],\n",
    "#         shape=(new_height, new_width)\n",
    "#     )\n",
    "\n",
    "#     # Create new lat/lon arrays\n",
    "#     new_lat = np.linspace(min_lat, max_lat, new_height)\n",
    "#     new_lon = np.linspace(min_lon, max_lon, new_width)\n",
    "\n",
    "#     # Assign these as coords on y/x\n",
    "#     resampled_ds = resampled_ds.assign_coords(y=(\"y\", new_lat), x=(\"x\", new_lon))\n",
    "\n",
    "#     # Rename dims/vars back to (latitude, longitude)\n",
    "#     resampled_ds = resampled_ds.rename_dims({\"y\": \"latitude\", \"x\": \"longitude\"})\n",
    "#     resampled_ds = resampled_ds.rename_vars({\"y\": \"latitude\", \"x\": \"longitude\"})\n",
    "\n",
    "#     # Mark them again as the spatial dims\n",
    "#     resampled_ds = resampled_ds.rio.set_spatial_dims(\n",
    "#         x_dim=\"longitude\", y_dim=\"latitude\", inplace=False\n",
    "#     )\n",
    "\n",
    "#     print(\"✅ Resampling completed with coordinates restored.\")\n",
    "#     return resampled_ds\n",
    "\n",
    "# def save_mosaic_to_tiff(ds, output_path, bounds):\n",
    "#     \"\"\"\n",
    "#     Saves an xarray.Dataset (with dims \"latitude\" and \"longitude\") \n",
    "#     to a multi-band GeoTIFF, using a bounding box transform.\n",
    "\n",
    "#     Parameters:\n",
    "#     - ds : xarray.Dataset with .rio CRS = EPSG:4326\n",
    "#     - output_path : str, path to save the GeoTIFF\n",
    "#     - bounds : tuple (min_lon, min_lat, max_lon, max_lat)\n",
    "#     \"\"\"\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "#     # Identify spatial variables: 2D variables\n",
    "#     spatial_vars = [var for var in ds.data_vars if ds[var].ndim == 2]\n",
    "\n",
    "#     if not spatial_vars:\n",
    "#         print(\"❌ No 2D spatial variables found to save.\")\n",
    "#         return\n",
    "\n",
    "#     # Ensure all spatial_vars have the same shape\n",
    "#     shapes = {ds[var].shape for var in spatial_vars}\n",
    "#     if len(shapes) != 1:\n",
    "#         print(\"❌ Not all spatial variables have the same shape.\")\n",
    "#         for var in spatial_vars:\n",
    "#             print(f\"{var}: shape={ds[var].shape}\")\n",
    "#         return\n",
    "\n",
    "#     # Rasterio transform, using # of pixels from ds and bounding box from 'bounds'\n",
    "#     width = ds.sizes[\"longitude\"]\n",
    "#     height = ds.sizes[\"latitude\"]\n",
    "#     transform = from_bounds(bounds[0], bounds[1], bounds[2], bounds[3], width, height)\n",
    "\n",
    "#     # Stack spatial_vars into (count, height, width)\n",
    "#     band_stack = np.stack([ds[var].values for var in spatial_vars])\n",
    "\n",
    "#     print(f\"Saving {len(spatial_vars)}-band GeoTIFF at: {output_path}\")\n",
    "#     with rasterio.open(\n",
    "#         output_path,\n",
    "#         \"w\",\n",
    "#         driver=\"GTiff\",\n",
    "#         height=height,\n",
    "#         width=width,\n",
    "#         count=len(spatial_vars),\n",
    "#         dtype=\"float32\",\n",
    "#         crs=\"EPSG:4326\",\n",
    "#         transform=transform,\n",
    "#         compress=\"lzw\"\n",
    "#     ) as dst:\n",
    "#         for i, var_name in enumerate(spatial_vars, start=1):\n",
    "#             dst.write(band_stack[i - 1], i)\n",
    "#             dst.set_band_description(i, var_name)\n",
    "\n",
    "#     print(f\"✅ Successfully saved: {output_path}\")\n",
    "\n",
    "#     # Print NaN statistics\n",
    "#     print(\"NaN Stats for each band:\")\n",
    "#     for var_name in spatial_vars:\n",
    "#         da = ds[var_name]\n",
    "#         nan_count = np.isnan(da.values).sum()\n",
    "#         total_count = da.size\n",
    "#         nan_percentage = (nan_count / total_count) * 100\n",
    "#         min_val = np.nanmin(da.values)\n",
    "#         max_val = np.nanmax(da.values)\n",
    "#         print(f\"  {var_name}: NaNs={nan_count}/{total_count} ({nan_percentage:.2f}%), Min={min_val:.4f}, Max={max_val:.4f}\")\n",
    "# def verify_output_tiff(tiff_path):\n",
    "#     \"\"\"\n",
    "#     Simple helper to check the existence and some metadata\n",
    "#     of the output GeoTIFF file.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         tiff_path = os.path.abspath(tiff_path)\n",
    "#         if not os.path.exists(tiff_path):\n",
    "#             print(f\"Error: File not found at {tiff_path}\")\n",
    "#             return False\n",
    "\n",
    "#         print(f\"\\nVerifying file at: {tiff_path}\")\n",
    "#         with rasterio.open(tiff_path) as src:\n",
    "#             print(f\"CRS: {src.crs}\")\n",
    "#             print(f\"Transform: {src.transform}\")\n",
    "#             print(f\"Bounds: {src.bounds}\")\n",
    "#             file_mb = os.path.getsize(tiff_path)/(1024*1024)\n",
    "#             print(f\"File size: {file_mb:.2f} MB\")\n",
    "\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error verifying TIFF: {e}\")\n",
    "#         return False\n",
    "# resampled_30m_ds = resample_to_30m(weighted_mosaic_data, method=\"bilinear\")\n",
    "# save_mosaic_to_tiff(resampled_30m_ds, \"/kaggle/working/sentinel_30m_billinear.tiff\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ef252a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.838293Z",
     "iopub.status.busy": "2025-08-19T17:21:47.837464Z",
     "iopub.status.idle": "2025-08-19T17:21:47.841227Z",
     "shell.execute_reply": "2025-08-19T17:21:47.840518Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2025-08-19T17:21:47.842603",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.822827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resampled_30m_ds = resample_to_30m(weighted_mosaic_data, method=\"cubic\")\n",
    "# save_mosaic_to_tiff(resampled_30m_ds, \"/kaggle/working/sentinel_30m_resampled_cubic.tiff\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01ae424d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.871712Z",
     "iopub.status.busy": "2025-08-19T17:21:47.871376Z",
     "iopub.status.idle": "2025-08-19T17:21:47.877173Z",
     "shell.execute_reply": "2025-08-19T17:21:47.876351Z"
    },
    "papermill": {
     "duration": 0.022067,
     "end_time": "2025-08-19T17:21:47.878647",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.856580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Weighted Temporal Mosaicking\n",
    "# # Assign weights based on cloud-free pixels (cloud mask using SCL band)\n",
    "# # weights = ~((data[\"SCL\"] == 8) | (data[\"SCL\"] == 9) | (data[\"SCL\"] == 10) | (data[\"SCL\"] == 11))\n",
    "\n",
    "# # # Calculate weighted mosaic\n",
    "# # weighted_mosaic = {}\n",
    "# # for band in data.data_vars.keys():\n",
    "# #     # if band != \"SCL\":  # Skip the SCL layer\n",
    "# #       weighted_mosaic[band] = (data[band] * weights).sum(dim=\"time\") / weights.sum(dim=\"time\")\n",
    "\n",
    "# # Convert the weighted mosaic to an Xarray dataset\n",
    "# scene = data.isel(time=8)          # or .sel(time='2023-07-25')\n",
    "\n",
    "# # 2. feed it straight into \"weighted_mosaic\" dict\n",
    "# weighted_mosaic = {band: scene[band] for band in scene.data_vars}\n",
    "\n",
    "# # Convert the weighted mosaic to an Xarray dataset\n",
    "# weighted_mosaic_data = xr.Dataset(weighted_mosaic)\n",
    "\n",
    "# for var in weighted_mosaic_data.data_vars:\n",
    "#     weighted_mosaic_data[var] = weighted_mosaic_data[var].astype(\"float32\")\n",
    "\n",
    "# # Add derived indices to the weighted mosaic\n",
    "# # weighted_mosaic_data[\"NDVI\"] = (weighted_mosaic_data.B08 - weighted_mosaic_data.B04) / (weighted_mosaic_data.B08 + weighted_mosaic_data.B04)\n",
    "# # weighted_mosaic_data[\"NDBI\"] = (weighted_mosaic_data.B11 - weighted_mosaic_data.B08) / (weighted_mosaic_data.B11 + weighted_mosaic_data.B08)\n",
    "# # weighted_mosaic_data[\"NDWI\"] = (weighted_mosaic_data.B03 - weighted_mosaic_data.B08) / (weighted_mosaic_data.B03 + weighted_mosaic_data.B08)\n",
    "# # weighted_mosaic_data[\"EVI\"] = 2.5 * ((weighted_mosaic_data.B08 - weighted_mosaic_data.B04) / (weighted_mosaic_data.B08 + 6 * weighted_mosaic_data.B04 - 7.5 * weighted_mosaic_data.B02 + 1))\n",
    "# # weighted_mosaic_data[\"SAVI\"] = ((weighted_mosaic_data.B08 - weighted_mosaic_data.B04) * 1.5) / (weighted_mosaic_data.B08 + weighted_mosaic_data.B04 + 0.5)\n",
    "# # weighted_mosaic_data[\"MSAVI\"] = (2 * weighted_mosaic_data.B08 + 1 - ((2 * weighted_mosaic_data.B08 + 1) ** 2 - 8 * (weighted_mosaic_data.B08 - weighted_mosaic_data.B04)) ** 0.5) / 2\n",
    "# # weighted_mosaic_data[\"GNDVI\"] = (weighted_mosaic_data.B08 - weighted_mosaic_data.B03) / (weighted_mosaic_data.B08 + weighted_mosaic_data.B03)\n",
    "# # weighted_mosaic_data[\"IBI\"] = (2 * weighted_mosaic_data.B11 - (weighted_mosaic_data.B08 + weighted_mosaic_data.B04)) / (weighted_mosaic_data.B11 + weighted_mosaic_data.B08 + weighted_mosaic_data.B04)\n",
    "# # weighted_mosaic_data[\"UI\"] = (weighted_mosaic_data.B08 + weighted_mosaic_data.B11) / (weighted_mosaic_data.B02 + weighted_mosaic_data.B03)\n",
    "# # weighted_mosaic_data[\"NDBSI\"] = (weighted_mosaic_data.B03 + weighted_mosaic_data.B11) / (weighted_mosaic_data.B08 + weighted_mosaic_data.B02)\n",
    "# # weighted_mosaic_data[\"NDMI\"] = (weighted_mosaic_data.B08 - weighted_mosaic_data.B11) / (weighted_mosaic_data.B08 + weighted_mosaic_data.B11)\n",
    "# # weighted_mosaic_data[\"NDSI\"] = (weighted_mosaic_data.B03 - weighted_mosaic_data.B11) / (weighted_mosaic_data.B03 + weighted_mosaic_data.B11)\n",
    "# # weighted_mosaic_data[\"BI\"] = (weighted_mosaic_data.B03 + weighted_mosaic_data.B04 + weighted_mosaic_data.B08 + weighted_mosaic_data.B11) / 4\n",
    "\n",
    "# # # Add new features\n",
    "# # weighted_mosaic_data[\"REP\"] = 705 + 35 * (((weighted_mosaic_data.B05 + weighted_mosaic_data.B07) / 2) - weighted_mosaic_data.B06) / (weighted_mosaic_data.B07 - weighted_mosaic_data.B05)\n",
    "# # weighted_mosaic_data[\"NGRDI\"] = (weighted_mosaic_data.B03 - weighted_mosaic_data.B04) / (weighted_mosaic_data.B03 + weighted_mosaic_data.B04)\n",
    "# # weighted_mosaic_data[\"MNDWI\"] = (weighted_mosaic_data.B03 - weighted_mosaic_data.B11) / (weighted_mosaic_data.B03 + weighted_mosaic_data.B11)\n",
    "# # weighted_mosaic_data[\"NDWI_Variant\"] = (weighted_mosaic_data.B03 - weighted_mosaic_data.B8A) / (weighted_mosaic_data.B03 + weighted_mosaic_data.B8A)\n",
    "# # weighted_mosaic_data[\"BSI\"] = (weighted_mosaic_data.B11 + weighted_mosaic_data.B04 - weighted_mosaic_data.B08 - weighted_mosaic_data.B02) / (weighted_mosaic_data.B11 + weighted_mosaic_data.B04 + weighted_mosaic_data.B08 + weighted_mosaic_data.B02)\n",
    "# # weighted_mosaic_data[\"SBI\"] = ((weighted_mosaic_data.B03 ** 2 + weighted_mosaic_data.B04 ** 2 + weighted_mosaic_data.B11 ** 2) ** 0.5)\n",
    "# # weighted_mosaic_data[\"Albedo\"] = (weighted_mosaic_data.B02 + weighted_mosaic_data.B03 + weighted_mosaic_data.B04 + weighted_mosaic_data.B8A + weighted_mosaic_data.B11) / 5\n",
    "# # weighted_mosaic_data[\"Vegetation_Ratio\"] = ((weighted_mosaic_data[\"SCL\"] == 4).sum(dim=[\"latitude\", \"longitude\"]) / weighted_mosaic_data[\"SCL\"].size) * 100\n",
    "# # weighted_mosaic_data[\"Bare_Soil_Ratio\"] = ((weighted_mosaic_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / weighted_mosaic_data[\"SCL\"].size) * 100\n",
    "# # weighted_mosaic_data[\"Water_Ratio\"] = ((weighted_mosaic_data[\"SCL\"] == 6).sum(dim=[\"latitude\", \"longitude\"]) / weighted_mosaic_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # # Simplified binary masks\n",
    "# # weighted_mosaic_data[\"Urban_Ratio\"] = ((weighted_mosaic_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / weighted_mosaic_data[\"SCL\"].size) * 100\n",
    "# # weighted_mosaic_data[\"Cloud_Shadow_Ratio\"] = ((weighted_mosaic_data[\"SCL\"] == 3).sum(dim=[\"latitude\", \"longitude\"]) / weighted_mosaic_data[\"SCL\"].size) * 100\n",
    "# # Save weighted mosaic to GeoTIFF\n",
    "# weighted_mosaic_tiff_path = \"Sentinel2_WeightedMosaic_(nbs).tiff\"\n",
    "# weighted_mosaic_data.rio.to_raster(weighted_mosaic_tiff_path, compress=\"lzw\")\n",
    "# print(f\"Weighted mosaic GeoTIFF with all features saved at {weighted_mosaic_tiff_path}\")\n",
    "\n",
    "# # save_resampled_weighted_mosaics(weighted_mosaic_data, output_prefix='/kaggle/working/Sentinel2_Mosaic_30m_no_base_sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afc9d7d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.908594Z",
     "iopub.status.busy": "2025-08-19T17:21:47.907566Z",
     "iopub.status.idle": "2025-08-19T17:21:47.911856Z",
     "shell.execute_reply": "2025-08-19T17:21:47.910993Z"
    },
    "papermill": {
     "duration": 0.020495,
     "end_time": "2025-08-19T17:21:47.913271",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.892776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resampled_30m_ds = resample_to_30m(weighted_mosaic_data, method=\"bilinear\")\n",
    "# save_mosaic_to_tiff(resampled_30m_ds, \"/kaggle/working/sentinel_30m_billinear(nbs).tiff\", bounds)\n",
    "\n",
    "# # resampled_30m_ds = resample_to_30m(weighted_mosaic_data, method=\"cubic\")\n",
    "# # save_mosaic_to_tiff(resampled_30m_ds, \"/kaggle/working/sentinel_30m_cubic(nbs).tiff\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a789a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.943008Z",
     "iopub.status.busy": "2025-08-19T17:21:47.942125Z",
     "iopub.status.idle": "2025-08-19T17:21:47.946610Z",
     "shell.execute_reply": "2025-08-19T17:21:47.945733Z"
    },
    "papermill": {
     "duration": 0.02075,
     "end_time": "2025-08-19T17:21:47.948097",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.927347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evi_median = (2.5 * ((median.B08 - median.B04) / (median.B08 + (6 * median.B04) - (7.5 * median.B02) + 1)))\n",
    "# L = 0.5  # Soil brightness correction factor\n",
    "# savi_median = (((median.B08 - median.B04) / (median.B08 + median.B04 + L)) * (1 + L))\n",
    "# msavi_median = (((2 * median.B08) + 1) - (((2 * median.B08 + 1) ** 2) - (8 * (median.B08 - median.B04))) ** 0.5) / 2\n",
    "# gndvi_median = ((median.B08 - median.B03) / (median.B08 + median.B03))\n",
    "\n",
    "# ibi_median = ((ndbi_median - (ndvi_median + ndwi_median)) / (ndbi_median + (ndvi_median + ndwi_median)))\n",
    "\n",
    "# ui_median = ((median.B11 - median.B08) / (median.B11 + median.B08))\n",
    "# ndbsi_median = ((ndbi_median + (1 - ndvi_median)) / 2)\n",
    "# ndmi_median = ((median.B08 - median.B11) / (median.B08 + median.B11))\n",
    "# ndsi_median = ((median.B03 - median.B11) / (median.B03 + median.B11))\n",
    "# bi_median = (((median.B04 ** 2) + (median.B03 ** 2) + (median.B02 ** 2)) ** 0.5) / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a1ccecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:47.977377Z",
     "iopub.status.busy": "2025-08-19T17:21:47.977052Z",
     "iopub.status.idle": "2025-08-19T17:21:47.982819Z",
     "shell.execute_reply": "2025-08-19T17:21:47.981959Z"
    },
    "papermill": {
     "duration": 0.022137,
     "end_time": "2025-08-19T17:21:47.984257",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.962120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_all_indices(indices_dict, vmin_vmax_dict, cmap_dict, title_dict):\n",
    "#     \"\"\"\n",
    "#     Plots all indices in subplots using a grid layout.\n",
    "\n",
    "#     Parameters:\n",
    "#     indices_dict: dict\n",
    "#         A dictionary where keys are index names (e.g., 'NDVI') and values are the calculated xarray indices.\n",
    "#     vmin_vmax_dict: dict\n",
    "#         A dictionary where keys are index names and values are tuples of (vmin, vmax) for color scale.\n",
    "#     cmap_dict: dict\n",
    "#         A dictionary where keys are index names and values are the colormap to use for each index.\n",
    "#     title_dict: dict\n",
    "#         A dictionary where keys are index names and values are the title for each plot.\n",
    "#     \"\"\"\n",
    "#     num_indices = len(indices_dict)\n",
    "#     ncols = 3  # Number of columns in the grid\n",
    "#     nrows = (num_indices + ncols - 1) // ncols  # Calculate rows needed for the grid\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5 * nrows))\n",
    "#     axes = axes.flatten()  # Flatten axes for easier iteration\n",
    "\n",
    "#     for i, (index_name, index_data) in enumerate(indices_dict.items()):\n",
    "#         ax = axes[i]\n",
    "#         index_data.plot.imshow(ax=ax, vmin=vmin_vmax_dict[index_name][0], \n",
    "#                                vmax=vmin_vmax_dict[index_name][1], cmap=cmap_dict[index_name])\n",
    "#         ax.set_title(title_dict[index_name])\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     # Hide any unused subplots\n",
    "#     for j in range(i + 1, len(axes)):\n",
    "#         fig.delaxes(axes[j])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Define all indices and their properties\n",
    "# indices_dict = {\n",
    "#     \"NDVI\": ndvi_median,\n",
    "#     \"NDWI\": ndwi_median,\n",
    "#     \"NDBI\": ndbi_median,\n",
    "#     \"EVI\": evi_median,\n",
    "#     \"SAVI\": savi_median,\n",
    "#     \"MSAVI\": msavi_median,\n",
    "#     \"GNDVI\": gndvi_median,\n",
    "#     \"IBI\": ibi_median,\n",
    "#     \"UI\": ui_median,\n",
    "#     \"NDBSI\": ndbsi_median,\n",
    "#     \"NDMI\": ndmi_median,\n",
    "#     \"NDSI\": ndsi_median,\n",
    "#     \"BI\": bi_median,\n",
    "# }\n",
    "\n",
    "# # Define vmin and vmax for each index\n",
    "# vmin_vmax_dict = {\n",
    "#     \"NDVI\": (0.0, 1.0),\n",
    "#     \"NDWI\": (-0.3, 0.3),\n",
    "#     \"NDBI\": (-0.1, 0.1),\n",
    "#     \"EVI\": (-1.0, 1.0),\n",
    "#     \"SAVI\": (0.0, 1.0),\n",
    "#     \"MSAVI\": (0.0, 1.0),\n",
    "#     \"GNDVI\": (0.0, 1.0),\n",
    "#     \"IBI\": (-1.0, 1.0),\n",
    "#     \"UI\": (-1.0, 1.0),\n",
    "#     \"NDBSI\": (0.0, 1.0),\n",
    "#     \"NDMI\": (-1.0, 1.0),\n",
    "#     \"NDSI\": (-1.0, 1.0),\n",
    "#     \"BI\": (0.0, 1.0),\n",
    "# }\n",
    "\n",
    "# # Define colormaps for each index\n",
    "# cmap_dict = {\n",
    "#     \"NDVI\": \"RdYlGn\",\n",
    "#     \"NDWI\": \"RdBu\",\n",
    "#     \"NDBI\": \"jet\",\n",
    "#     \"EVI\": \"RdYlGn\",\n",
    "#     \"SAVI\": \"RdYlGn\",\n",
    "#     \"MSAVI\": \"RdYlGn\",\n",
    "#     \"GNDVI\": \"RdYlGn\",\n",
    "#     \"IBI\": \"coolwarm\",\n",
    "#     \"UI\": \"coolwarm\",\n",
    "#     \"NDBSI\": \"YlOrRd\",\n",
    "#     \"NDMI\": \"PiYG\",\n",
    "#     \"NDSI\": \"BrBG\",\n",
    "#     \"BI\": \"cividis\",\n",
    "# }\n",
    "\n",
    "# # Define titles for each index\n",
    "# title_dict = {\n",
    "#     \"NDVI\": \"Normalized Difference Vegetation Index (NDVI)\",\n",
    "#     \"NDWI\": \"Normalized Difference Water Index (NDWI)\",\n",
    "#     \"NDBI\": \"Normalized Difference Built-Up Index (NDBI)\",\n",
    "#     \"EVI\": \"Enhanced Vegetation Index (EVI)\",\n",
    "#     \"SAVI\": \"Soil-Adjusted Vegetation Index (SAVI)\",\n",
    "#     \"MSAVI\": \"Modified Soil-Adjusted Vegetation Index (MSAVI)\",\n",
    "#     \"GNDVI\": \"Green Normalized Difference Vegetation Index (GNDVI)\",\n",
    "#     \"IBI\": \"Index-Based Built-Up Index (IBI)\",\n",
    "#     \"UI\": \"Urban Index (UI)\",\n",
    "#     \"NDBSI\": \"Normalized Difference Bare Soil Index (NDBSI)\",\n",
    "#     \"NDMI\": \"Normalized Difference Moisture Index (NDMI)\",\n",
    "#     \"NDSI\": \"Normalized Difference Snow Index (NDSI)\",\n",
    "#     \"BI\": \"Brightness Index (BI)\",\n",
    "# }\n",
    "\n",
    "# # Call the function to plot all indices\n",
    "# # plot_all_indices(indices_dict, vmin_vmax_dict, cmap_dict, title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c057800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.013890Z",
     "iopub.status.busy": "2025-08-19T17:21:48.013095Z",
     "iopub.status.idle": "2025-08-19T17:21:48.018349Z",
     "shell.execute_reply": "2025-08-19T17:21:48.017486Z"
    },
    "papermill": {
     "duration": 0.021484,
     "end_time": "2025-08-19T17:21:48.019763",
     "exception": false,
     "start_time": "2025-08-19T17:21:47.998279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean_data = data.mean(dim='time').compute()\n",
    "\n",
    "# # bands_only_path_mean = \"Sentinel2_Mean_Only_Bands.tiff\"\n",
    "# # mean_data.rio.to_raster(bands_only_path_mean, compress=\"lzw\")\n",
    "# # print(f\"Mean GeoTIFF with only bands saved at {bands_only_path_mean}\")\n",
    "\n",
    "# # Add all derived indices directly\n",
    "# mean_data[\"NDVI\"] = (mean_data.B08 - mean_data.B04) / (mean_data.B08 + mean_data.B04)\n",
    "# mean_data[\"NDBI\"] = (mean_data.B11 - mean_data.B08) / (mean_data.B11 + mean_data.B08)\n",
    "# mean_data[\"NDWI\"] = (mean_data.B03 - mean_data.B08) / (mean_data.B03 + mean_data.B08)\n",
    "# mean_data[\"EVI\"] = 2.5 * ((mean_data.B08 - mean_data.B04) / (mean_data.B08 + 6 * mean_data.B04 - 7.5 * mean_data.B02 + 1))\n",
    "# mean_data[\"SAVI\"] = ((mean_data.B08 - mean_data.B04) * 1.5) / (mean_data.B08 + mean_data.B04 + 0.5)\n",
    "# mean_data[\"MSAVI\"] = (2 * mean_data.B08 + 1 - ((2 * mean_data.B08 + 1) ** 2 - 8 * (mean_data.B08 - mean_data.B04)) ** 0.5) / 2\n",
    "# mean_data[\"GNDVI\"] = (mean_data.B08 - mean_data.B03) / (mean_data.B08 + mean_data.B03)\n",
    "# mean_data[\"IBI\"] = (2 * mean_data.B11 - (mean_data.B08 + mean_data.B04)) / (mean_data.B11 + mean_data.B08 + mean_data.B04)\n",
    "# mean_data[\"UI\"] = (mean_data.B08 + mean_data.B11) / (mean_data.B02 + mean_data.B03)\n",
    "# mean_data[\"NDBSI\"] = (mean_data.B03 + mean_data.B11) / (mean_data.B08 + mean_data.B02)\n",
    "# mean_data[\"NDMI\"] = (mean_data.B08 - mean_data.B11) / (mean_data.B08 + mean_data.B11)\n",
    "# mean_data[\"NDSI\"] = (mean_data.B03 - mean_data.B11) / (mean_data.B03 + mean_data.B11)\n",
    "# mean_data[\"BI\"] = (mean_data.B03 + mean_data.B04 + mean_data.B08 + mean_data.B11) / 4\n",
    "\n",
    "# mean_data[\"REP\"] = 705 + 35 * (((mean_data.B05 + mean_data.B07) / 2) - mean_data.B06) / (mean_data.B07 - mean_data.B05)\n",
    "# mean_data[\"NGRDI\"] = (mean_data.B03 - mean_data.B04) / (mean_data.B03 + mean_data.B04)\n",
    "# mean_data[\"MNDWI\"] = (mean_data.B03 - mean_data.B11) / (mean_data.B03 + mean_data.B11)\n",
    "# mean_data[\"NDWI_Variant\"] = (mean_data.B03 - mean_data.B8A) / (mean_data.B03 + mean_data.B8A)\n",
    "# mean_data[\"BSI\"] = (mean_data.B11 + mean_data.B04 - mean_data.B08 - mean_data.B02) / (mean_data.B11 + mean_data.B04 + mean_data.B08 + mean_data.B02)\n",
    "# mean_data[\"SBI\"] = ((mean_data.B03 ** 2 + mean_data.B04 ** 2 + mean_data.B11 ** 2) ** 0.5)\n",
    "# mean_data[\"Albedo\"] = (mean_data.B02 + mean_data.B03 + mean_data.B04 + mean_data.B8A + mean_data.B11) / 5\n",
    "\n",
    "# mean_data[\"Vegetation_Ratio\"] = ((mean_data[\"SCL\"] == 4).sum(dim=[\"latitude\", \"longitude\"]) / mean_data[\"SCL\"].size) * 100\n",
    "# mean_data[\"Bare_Soil_Ratio\"] = ((mean_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / mean_data[\"SCL\"].size) * 100\n",
    "# mean_data[\"Water_Ratio\"] = ((mean_data[\"SCL\"] == 6).sum(dim=[\"latitude\", \"longitude\"]) / mean_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # Simplified binary masks\n",
    "# mean_data[\"Urban_Ratio\"] = ((mean_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / mean_data[\"SCL\"].size) * 100\n",
    "# mean_data[\"Cloud_Shadow_Ratio\"] = ((mean_data[\"SCL\"] == 3).sum(dim=[\"latitude\", \"longitude\"]) / mean_data[\"SCL\"].size) * 100\n",
    "# # Save median composite to a GeoTIFF file\n",
    "# mean_tiff_path = \"Sentinel2_Mean_All_Bands_and_Indices.tiff\"\n",
    "# mean_data.rio.to_raster(mean_tiff_path, compress=\"lzw\")\n",
    "# print(f\"Mean GeoTIFF saved at {mean_tiff_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcea3bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.050932Z",
     "iopub.status.busy": "2025-08-19T17:21:48.050341Z",
     "iopub.status.idle": "2025-08-19T17:21:48.054280Z",
     "shell.execute_reply": "2025-08-19T17:21:48.053513Z"
    },
    "papermill": {
     "duration": 0.020465,
     "end_time": "2025-08-19T17:21:48.055897",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.035432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# mean_data[[\"B04\", \"B03\", \"B02\"]].to_array().plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"RGB Mean Composite\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96a5812a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.085931Z",
     "iopub.status.busy": "2025-08-19T17:21:48.085126Z",
     "iopub.status.idle": "2025-08-19T17:21:48.090341Z",
     "shell.execute_reply": "2025-08-19T17:21:48.089584Z"
    },
    "papermill": {
     "duration": 0.021564,
     "end_time": "2025-08-19T17:21:48.091702",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.070138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save Median Composite GeoTIFF\n",
    "# # Calculate the median composite\n",
    "# median_data = data.median(dim=\"time\").compute()\n",
    "\n",
    "# # Save version with only spectral bands\n",
    "# # bands_only_path_median = \"Sentinel2_Median_Only_Bands.tiff\"\n",
    "# # median_data.rio.to_raster(bands_only_path_median, compress=\"lzw\")\n",
    "# # print(f\"Median GeoTIFF with only bands saved at {bands_only_path_median}\")\n",
    "\n",
    "# # Add all derived indices directly\n",
    "# median_data[\"NDVI\"] = (median_data.B08 - median_data.B04) / (median_data.B08 + median_data.B04)\n",
    "# median_data[\"NDBI\"] = (median_data.B11 - median_data.B08) / (median_data.B11 + median_data.B08)\n",
    "# median_data[\"NDWI\"] = (median_data.B03 - median_data.B08) / (median_data.B03 + median_data.B08)\n",
    "# median_data[\"EVI\"] = 2.5 * ((median_data.B08 - median_data.B04) / (median_data.B08 + 6 * median_data.B04 - 7.5 * median_data.B02 + 1))\n",
    "# median_data[\"SAVI\"] = ((median_data.B08 - median_data.B04) * 1.5) / (median_data.B08 + median_data.B04 + 0.5)\n",
    "# median_data[\"MSAVI\"] = (2 * median_data.B08 + 1 - ((2 * median_data.B08 + 1) ** 2 - 8 * (median_data.B08 - median_data.B04)) ** 0.5) / 2\n",
    "# median_data[\"GNDVI\"] = (median_data.B08 - median_data.B03) / (median_data.B08 + median_data.B03)\n",
    "# median_data[\"IBI\"] = (2 * median_data.B11 - (median_data.B08 + median_data.B04)) / (median_data.B11 + median_data.B08 + median_data.B04)\n",
    "# median_data[\"UI\"] = (median_data.B08 + median_data.B11) / (median_data.B02 + median_data.B03)\n",
    "# median_data[\"NDBSI\"] = (median_data.B03 + median_data.B11) / (median_data.B08 + median_data.B02)\n",
    "# median_data[\"NDMI\"] = (median_data.B08 - median_data.B11) / (median_data.B08 + median_data.B11)\n",
    "# median_data[\"NDSI\"] = (median_data.B03 - median_data.B11) / (median_data.B03 + median_data.B11)\n",
    "# median_data[\"BI\"] = (median_data.B03 + median_data.B04 + median_data.B08 + median_data.B11) / 4\n",
    "\n",
    "# median_data[\"REP\"] = 705 + 35 * (((median_data.B05 + median_data.B07) / 2) - median_data.B06) / (median_data.B07 - median_data.B05)\n",
    "# median_data[\"NGRDI\"] = (median_data.B03 - median_data.B04) / (median_data.B03 + median_data.B04)\n",
    "# median_data[\"MNDWI\"] = (median_data.B03 - median_data.B11) / (median_data.B03 + median_data.B11)\n",
    "# median_data[\"NDWI_Variant\"] = (median_data.B03 - median_data.B8A) / (median_data.B03 + median_data.B8A)\n",
    "# median_data[\"BSI\"] = (median_data.B11 + median_data.B04 - median_data.B08 - median_data.B02) / (median_data.B11 + median_data.B04 + median_data.B08 + median_data.B02)\n",
    "# median_data[\"SBI\"] = ((median_data.B03 ** 2 + median_data.B04 ** 2 + median_data.B11 ** 2) ** 0.5)\n",
    "# median_data[\"Albedo\"] = (median_data.B02 + median_data.B03 + median_data.B04 + median_data.B8A + median_data.B11) / 5\n",
    "\n",
    "# median_data[\"Vegetation_Ratio\"] = ((median_data[\"SCL\"] == 4).sum(dim=[\"latitude\", \"longitude\"]) / median_data[\"SCL\"].size) * 100\n",
    "# median_data[\"Bare_Soil_Ratio\"] = ((median_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / median_data[\"SCL\"].size) * 100\n",
    "# median_data[\"Water_Ratio\"] = ((median_data[\"SCL\"] == 6).sum(dim=[\"latitude\", \"longitude\"]) / median_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # Simplified binary masks\n",
    "# median_data[\"Urban_Ratio\"] = ((median_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / median_data[\"SCL\"].size) * 100\n",
    "# median_data[\"Cloud_Shadow_Ratio\"] = ((median_data[\"SCL\"] == 3).sum(dim=[\"latitude\", \"longitude\"]) / median_data[\"SCL\"].size) * 100\n",
    "# # Save median composite to a GeoTIFF file\n",
    "# median_tiff_path = \"Sentinel2_Median_All_Bands_and_Indices.tiff\"\n",
    "# median_data.rio.to_raster(median_tiff_path, compress=\"lzw\")\n",
    "# print(f\"Median GeoTIFF saved at {median_tiff_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4d67adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.120819Z",
     "iopub.status.busy": "2025-08-19T17:21:48.120532Z",
     "iopub.status.idle": "2025-08-19T17:21:48.124232Z",
     "shell.execute_reply": "2025-08-19T17:21:48.123546Z"
    },
    "papermill": {
     "duration": 0.019595,
     "end_time": "2025-08-19T17:21:48.125521",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.105926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# median_data[[\"B04\", \"B03\", \"B02\"]].to_array().plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"RGB Median Composite\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "187d23d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.154959Z",
     "iopub.status.busy": "2025-08-19T17:21:48.154645Z",
     "iopub.status.idle": "2025-08-19T17:21:48.159991Z",
     "shell.execute_reply": "2025-08-19T17:21:48.159177Z"
    },
    "papermill": {
     "duration": 0.021771,
     "end_time": "2025-08-19T17:21:48.161358",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.139587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save Single-Date GeoTIFF\n",
    "# # Select the specific date (2021-07-24)\n",
    "# single_date_index = 6  # Ensure this index corresponds to the correct date\n",
    "# single_date_data = data.isel(time=single_date_index)\n",
    "\n",
    "# # Save version with only spectral bands\n",
    "# # bands_only_path_single = \"Sentinel2_SingleDate_Only_Bands.tiff\"\n",
    "# # single_date_data.rio.to_raster(bands_only_path_single, compress=\"lzw\")\n",
    "# # print(f\"Single-date GeoTIFF with only bands saved at {bands_only_path_single}\")\n",
    "\n",
    "# # Add all derived indices directly\n",
    "# single_date_data[\"NDVI\"] = (single_date_data.B08 - single_date_data.B04) / (single_date_data.B08 + single_date_data.B04)\n",
    "# single_date_data[\"NDBI\"] = (single_date_data.B11 - single_date_data.B08) / (single_date_data.B11 + single_date_data.B08)\n",
    "# single_date_data[\"NDWI\"] = (single_date_data.B03 - single_date_data.B08) / (single_date_data.B03 + single_date_data.B08)\n",
    "# single_date_data[\"EVI\"] = 2.5 * ((single_date_data.B08 - single_date_data.B04) / (single_date_data.B08 + 6 * single_date_data.B04 - 7.5 * single_date_data.B02 + 1))\n",
    "# single_date_data[\"SAVI\"] = ((single_date_data.B08 - single_date_data.B04) * 1.5) / (single_date_data.B08 + single_date_data.B04 + 0.5)\n",
    "# single_date_data[\"MSAVI\"] = (2 * single_date_data.B08 + 1 - ((2 * single_date_data.B08 + 1) ** 2 - 8 * (single_date_data.B08 - single_date_data.B04)) ** 0.5) / 2\n",
    "# single_date_data[\"GNDVI\"] = (single_date_data.B08 - single_date_data.B03) / (single_date_data.B08 + single_date_data.B03)\n",
    "# single_date_data[\"IBI\"] = (2 * single_date_data.B11 - (single_date_data.B08 + single_date_data.B04)) / (single_date_data.B11 + single_date_data.B08 + single_date_data.B04)\n",
    "# single_date_data[\"UI\"] = (single_date_data.B08 + single_date_data.B11) / (single_date_data.B02 + single_date_data.B03)\n",
    "# single_date_data[\"NDBSI\"] = (single_date_data.B03 + single_date_data.B11) / (single_date_data.B08 + single_date_data.B02)\n",
    "# single_date_data[\"NDMI\"] = (single_date_data.B08 - single_date_data.B11) / (single_date_data.B08 + single_date_data.B11)\n",
    "# single_date_data[\"NDSI\"] = (single_date_data.B03 - single_date_data.B11) / (single_date_data.B03 + single_date_data.B11)\n",
    "# single_date_data[\"BI\"] = (single_date_data.B03 + single_date_data.B04 + single_date_data.B08 + single_date_data.B11) / 4\n",
    "# single_date_data[\"REP\"] = 705 + 35 * (((single_date_data.B05 + single_date_data.B07) / 2) - single_date_data.B06) / (single_date_data.B07 - single_date_data.B05)\n",
    "# single_date_data[\"NGRDI\"] = (single_date_data.B03 - single_date_data.B04) / (single_date_data.B03 + single_date_data.B04)\n",
    "# single_date_data[\"MNDWI\"] = (single_date_data.B03 - single_date_data.B11) / (single_date_data.B03 + single_date_data.B11)\n",
    "# single_date_data[\"NDWI_Variant\"] = (single_date_data.B03 - single_date_data.B8A) / (single_date_data.B03 + single_date_data.B8A)\n",
    "# single_date_data[\"BSI\"] = (single_date_data.B11 + single_date_data.B04 - single_date_data.B08 - single_date_data.B02) / (single_date_data.B11 + single_date_data.B04 + single_date_data.B08 + single_date_data.B02)\n",
    "# single_date_data[\"SBI\"] = ((single_date_data.B03 ** 2 + single_date_data.B04 ** 2 + single_date_data.B11 ** 2) ** 0.5)\n",
    "# single_date_data[\"Albedo\"] = (single_date_data.B02 + single_date_data.B03 + single_date_data.B04 + single_date_data.B8A + single_date_data.B11) / 5\n",
    "# single_date_data[\"Vegetation_Ratio\"] = ((single_date_data[\"SCL\"] == 4).sum(dim=[\"latitude\", \"longitude\"]) / single_date_data[\"SCL\"].size) * 100\n",
    "# single_date_data[\"Bare_Soil_Ratio\"] = ((single_date_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / single_date_data[\"SCL\"].size) * 100\n",
    "# single_date_data[\"Water_Ratio\"] = ((single_date_data[\"SCL\"] == 6).sum(dim=[\"latitude\", \"longitude\"]) / single_date_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # Simplified binary masks\n",
    "# single_date_data[\"Urban_Ratio\"] = ((single_date_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / single_date_data[\"SCL\"].size) * 100\n",
    "# single_date_data[\"Cloud_Shadow_Ratio\"] = ((single_date_data[\"SCL\"] == 3).sum(dim=[\"latitude\", \"longitude\"]) / single_date_data[\"SCL\"].size) * 100\n",
    "# # Save single-date data to a GeoTIFF file\n",
    "# single_date_tiff_path = \"Sentinel2_SingleDate_All_Bands_and_Indices.tiff\"\n",
    "# single_date_data.rio.to_raster(single_date_tiff_path, compress=\"lzw\")\n",
    "# print(f\"Single-date GeoTIFF saved at {single_date_tiff_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c631fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.190909Z",
     "iopub.status.busy": "2025-08-19T17:21:48.190601Z",
     "iopub.status.idle": "2025-08-19T17:21:48.194814Z",
     "shell.execute_reply": "2025-08-19T17:21:48.193947Z"
    },
    "papermill": {
     "duration": 0.020904,
     "end_time": "2025-08-19T17:21:48.196474",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.175570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# single_date_data[[\"B04\", \"B03\", \"B02\"]].to_array().plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500)\n",
    "# ax.set_title(\"RGB Single date(24-July-2024) Composite\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a9aeda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.228333Z",
     "iopub.status.busy": "2025-08-19T17:21:48.227959Z",
     "iopub.status.idle": "2025-08-19T17:21:48.233850Z",
     "shell.execute_reply": "2025-08-19T17:21:48.232995Z"
    },
    "papermill": {
     "duration": 0.023959,
     "end_time": "2025-08-19T17:21:48.235342",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.211383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# # Select the specific date (2021-07-24)\n",
    "# single_date_masked_index = 6  # Ensure this index corresponds to the correct date\n",
    "# single_date_masked_data = data.isel(time=single_date_masked_index)\n",
    "\n",
    "# # Apply Cloud Masking (using SCL band)\n",
    "# cloud_mask = ~((single_date_masked_data[\"SCL\"] == 8) | (single_date_masked_data[\"SCL\"] == 9) | (single_date_masked_data[\"SCL\"] == 10) | (single_date_masked_data[\"SCL\"] == 11))\n",
    "# for band in single_date_masked_data.data_vars:\n",
    "#     if band != \"SCL\":  # Skip the SCL layer\n",
    "#         single_date_masked_data[band] = single_date_masked_data[band].where(cloud_mask)\n",
    "\n",
    "# # Add all derived indices directly\n",
    "# single_date_masked_data[\"NDVI\"] = (single_date_masked_data.B08 - single_date_masked_data.B04) / (single_date_masked_data.B08 + single_date_masked_data.B04)\n",
    "# single_date_masked_data[\"NDBI\"] = (single_date_masked_data.B11 - single_date_masked_data.B08) / (single_date_masked_data.B11 + single_date_masked_data.B08)\n",
    "# single_date_masked_data[\"NDWI\"] = (single_date_masked_data.B03 - single_date_masked_data.B08) / (single_date_masked_data.B03 + single_date_masked_data.B08)\n",
    "# single_date_masked_data[\"EVI\"] = 2.5 * ((single_date_masked_data.B08 - single_date_masked_data.B04) / (single_date_masked_data.B08 + 6 * single_date_masked_data.B04 - 7.5 * single_date_masked_data.B02 + 1))\n",
    "# single_date_masked_data[\"SAVI\"] = ((single_date_masked_data.B08 - single_date_masked_data.B04) * 1.5) / (single_date_masked_data.B08 + single_date_masked_data.B04 + 0.5)\n",
    "# single_date_masked_data[\"MSAVI\"] = (2 * single_date_masked_data.B08 + 1 - ((2 * single_date_masked_data.B08 + 1) ** 2 - 8 * (single_date_masked_data.B08 - single_date_masked_data.B04)) ** 0.5) / 2\n",
    "# single_date_masked_data[\"GNDVI\"] = (single_date_masked_data.B08 - single_date_masked_data.B03) / (single_date_masked_data.B08 + single_date_masked_data.B03)\n",
    "# single_date_masked_data[\"IBI\"] = (2 * single_date_masked_data.B11 - (single_date_masked_data.B08 + single_date_masked_data.B04)) / (single_date_masked_data.B11 + single_date_masked_data.B08 + single_date_masked_data.B04)\n",
    "# single_date_masked_data[\"UI\"] = (single_date_masked_data.B08 + single_date_masked_data.B11) / (single_date_masked_data.B02 + single_date_masked_data.B03)\n",
    "# single_date_masked_data[\"NDBSI\"] = (single_date_masked_data.B03 + single_date_masked_data.B11) / (single_date_masked_data.B08 + single_date_masked_data.B02)\n",
    "# single_date_masked_data[\"NDMI\"] = (single_date_masked_data.B08 - single_date_masked_data.B11) / (single_date_masked_data.B08 + single_date_masked_data.B11)\n",
    "# single_date_masked_data[\"NDSI\"] = (single_date_masked_data.B03 - single_date_masked_data.B11) / (single_date_masked_data.B03 + single_date_masked_data.B11)\n",
    "# single_date_masked_data[\"BI\"] = (single_date_masked_data.B03 + single_date_masked_data.B04 + single_date_masked_data.B08 + single_date_masked_data.B11) / 4\n",
    "\n",
    "# single_date_masked_data[\"REP\"] = 705 + 35 * (((single_date_masked_data.B05 + single_date_masked_data.B07) / 2) - single_date_masked_data.B06) / (single_date_masked_data.B07 - single_date_masked_data.B05)\n",
    "# single_date_masked_data[\"NGRDI\"] = (single_date_masked_data.B03 - single_date_masked_data.B04) / (single_date_masked_data.B03 + single_date_masked_data.B04)\n",
    "# single_date_masked_data[\"MNDWI\"] = (single_date_masked_data.B03 - single_date_masked_data.B11) / (single_date_masked_data.B03 + single_date_masked_data.B11)\n",
    "# single_date_masked_data[\"NDWI_Variant\"] = (single_date_masked_data.B03 - single_date_masked_data.B8A) / (single_date_masked_data.B03 + single_date_masked_data.B8A)\n",
    "# single_date_masked_data[\"BSI\"] = (single_date_masked_data.B11 + single_date_masked_data.B04 - single_date_masked_data.B08 - single_date_masked_data.B02) / (single_date_masked_data.B11 + single_date_masked_data.B04 + single_date_masked_data.B08 + single_date_masked_data.B02)\n",
    "# single_date_masked_data[\"SBI\"] = ((single_date_masked_data.B03 ** 2 + single_date_masked_data.B04 ** 2 + single_date_masked_data.B11 ** 2) ** 0.5)\n",
    "# single_date_masked_data[\"Albedo\"] = (single_date_masked_data.B02 + single_date_masked_data.B03 + single_date_masked_data.B04 + single_date_masked_data.B8A + single_date_masked_data.B11) / 5\n",
    "# single_date_masked_data[\"Cloud_Percentage\"] = (cloud_mask.sum() / single_date_masked_data[\"SCL\"].size) * 100\n",
    "# single_date_masked_data[\"Vegetation_Ratio\"] = ((single_date_masked_data[\"SCL\"] == 4).sum(dim=[\"latitude\", \"longitude\"]) / single_date_masked_data[\"SCL\"].size) * 100\n",
    "# single_date_masked_data[\"Bare_Soil_Ratio\"] = ((single_date_masked_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / single_date_masked_data[\"SCL\"].size) * 100\n",
    "# single_date_masked_data[\"Water_Ratio\"] = ((single_date_masked_data[\"SCL\"] == 6).sum(dim=[\"latitude\", \"longitude\"]) / single_date_masked_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # Simplified binary masks\n",
    "# single_date_masked_data[\"Urban_Ratio\"] = ((single_date_masked_data[\"SCL\"] == 5).sum(dim=[\"latitude\", \"longitude\"]) / single_date_masked_data[\"SCL\"].size) * 100\n",
    "# single_date_masked_data[\"Cloud_Shadow_Ratio\"] = ((single_date_masked_data[\"SCL\"] == 3).sum(dim=[\"latitude\", \"longitude\"]) / single_date_masked_data[\"SCL\"].size) * 100\n",
    "\n",
    "# # Save single-date data to a GeoTIFF file\n",
    "# single_date_masked_tiff_path = \"Sentinel2_SingleDate_CloudMasked_All_Bands_and_Indices.tiff\"\n",
    "# single_date_masked_data.rio.to_raster(single_date_masked_tiff_path, compress=\"lzw\")\n",
    "# print(f\"Single-date GeoTIFF with cloud masking saved at {single_date_masked_tiff_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1b5caf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.265495Z",
     "iopub.status.busy": "2025-08-19T17:21:48.264672Z",
     "iopub.status.idle": "2025-08-19T17:21:48.268983Z",
     "shell.execute_reply": "2025-08-19T17:21:48.268143Z"
    },
    "papermill": {
     "duration": 0.020771,
     "end_time": "2025-08-19T17:21:48.270457",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.249686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot the SCL band to verify cloud classification\n",
    "# single_date_masked_data[\"SCL\"].plot(cmap=\"viridis\", robust=True)\n",
    "# plt.title(\"SCL Band for Cloud Classification\")\n",
    "# plt.show()\n",
    "\n",
    "# # Ensure Dask arrays are computed first\n",
    "# nan_count = single_date_masked_data[\"B04\"].isnull().sum().compute()  # Total NaN count\n",
    "# total_count = single_date_masked_data[\"B04\"].size  # Total number of elements in the array\n",
    "\n",
    "# # Calculate NaN percentage\n",
    "# nan_percentage = (nan_count / total_count) * 100\n",
    "# print(f\"Percentage of NaN values in B04 (masked): {nan_percentage:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8320aaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T17:21:48.299606Z",
     "iopub.status.busy": "2025-08-19T17:21:48.299294Z",
     "iopub.status.idle": "2025-08-19T17:21:48.303079Z",
     "shell.execute_reply": "2025-08-19T17:21:48.302284Z"
    },
    "papermill": {
     "duration": 0.019997,
     "end_time": "2025-08-19T17:21:48.304548",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.284551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# rgb = single_date_masked_data[[\"B04\", \"B03\", \"B02\"]].to_array()\n",
    "\n",
    "# rgb.plot.imshow(robust=True, ax=ax, vmin=0, vmax=2500, cmap=\"viridis\", add_colorbar=True)\n",
    "# ax.set_title(\"RGB Single Date with Cloud Masking (24-July-2024)\")\n",
    "# ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d02616",
   "metadata": {
    "papermill": {
     "duration": 0.01379,
     "end_time": "2025-08-19T17:21:48.332431",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.318641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f73ebd",
   "metadata": {
    "papermill": {
     "duration": 0.013667,
     "end_time": "2025-08-19T17:21:48.360102",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.346435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30147e41",
   "metadata": {
    "papermill": {
     "duration": 0.013665,
     "end_time": "2025-08-19T17:21:48.387587",
     "exception": false,
     "start_time": "2025-08-19T17:21:48.373922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2149.078275,
   "end_time": "2025-08-19T17:21:50.788369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-19T16:46:01.710094",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
